{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": " Stephen Kiilu day2-lab-extra-fairseq-demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenkiilu/NLP_Week2/blob/main/Stephen_Kiilu_day2_lab_extra_fairseq_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbNPO5Toi8rC"
      },
      "source": [
        "# Fairseq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9zKnOrgi8rI"
      },
      "source": [
        "from https://fairseq.readthedocs.io/en/latest/getting_started.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM6XXIRgi8rJ"
      },
      "source": [
        "\"Fairseq(-py) is a sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling and other text generation tasks.\" It provides reference implementations of various sequence-to-sequence models making our life much more easier!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM11T-d7i8rJ"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBC0Fkjni8rK"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSD2XoxFi8rK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5988cd7e-0166-46b0-996a-c9a0097ecfe8"
      },
      "source": [
        "!pip install --upgrade fairseq\n",
        "!pip install sacremoses subword_nmt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairseq\n",
            "  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.21.6)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.28)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.15.0)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 18.3 MB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.64.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2019.12.20)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.21)\n",
            "Collecting omegaconf==2.1.*\n",
            "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting importlib-resources<5.3\n",
            "  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 52.0 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources<5.3->hydra-core->fairseq) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq) (4.2.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=4f50a44ef0bffba6fc501c66a7d1391cf26b1640e10afe59f29a9af887cbd1a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, antlr4-python3-runtime, portalocker, omegaconf, importlib-resources, colorama, sacrebleu, hydra-core, dataclasses, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.7.1\n",
            "    Uninstalling importlib-resources-5.7.1:\n",
            "      Successfully uninstalled importlib-resources-5.7.1\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 colorama-0.4.4 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.1.2 importlib-resources-5.2.3 omegaconf-2.1.2 portalocker-2.4.0 sacrebleu-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 163 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 194 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 204 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 225 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 235 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 256 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 266 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 276 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 286 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 296 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 307 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 317 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 327 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 337 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 348 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 358 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 368 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 378 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 389 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 399 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 409 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 419 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 430 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 440 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 450 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 460 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 471 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 481 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 491 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 501 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 512 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 522 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 532 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 542 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 552 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 563 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 573 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 583 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 593 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 604 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 614 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 624 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 634 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 645 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 655 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 665 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 675 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 686 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 696 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 706 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 716 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 727 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 737 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 747 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 757 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 768 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 778 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 788 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 798 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 808 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 819 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 829 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 839 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 849 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 860 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 870 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 880 kB 24.3 MB/s \n",
            "\u001b[?25hCollecting subword_nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=05e0cccb7254353000b94dcf7e545d1d8763c447ce5dd68fc92b6a6234239b2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: mock, subword-nmt, sacremoses\n",
            "Successfully installed mock-4.0.3 sacremoses-0.0.53 subword-nmt-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3gTFLU8i8rK"
      },
      "source": [
        "## Generation using pre-trained MT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUbTNqX3i8rL",
        "outputId": "be67bb15-7186-4faa-f706-5db7e8921828"
      },
      "source": [
        "! curl https://dl.fbaipublicfiles.com/fairseq/models/wmt14.v2.en-fr.fconv-py.tar.bz2 | tar xvjf -"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0 1909M    0 11892    0     0  20753      0 26:48:01 --:--:-- 26:48:01 20717wmt14.en-fr.fconv-py/\n",
            "wmt14.en-fr.fconv-py/model.pt\n",
            " 99 1909M   99 1901M    0     0  7537k      0  0:04:19  0:04:18  0:00:01 8258kwmt14.en-fr.fconv-py/dict.en.txt\n",
            "wmt14.en-fr.fconv-py/dict.fr.txt\n",
            "100 1909M  100 1909M    0     0  7540k      0  0:04:19  0:04:19 --:--:-- 8323k\n",
            "wmt14.en-fr.fconv-py/bpecodes\n",
            "wmt14.en-fr.fconv-py/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhOle-js7dui"
      },
      "source": [
        "We're going to use this downloaded model in an interactive setting and try out all the decoding algorithms we learnt about! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-xWsnQvDz1t"
      },
      "source": [
        "##### First lets try out standard beam search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Lqv_NHFopk",
        "outputId": "b92608fc-2613-4e1d-ff75-81abe69fce1f"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --beam 5 --nbest 5 --source-lang en --target-lang fr --remove-bpe "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-17 07:00:49 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2022-05-17 07:00:49 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2022-05-17 07:00:49 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2022-05-17 07:00:49 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2022-05-17 07:01:01 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-05-17 07:01:01 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.363\tseconds\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -0.9387 -0.7073 -0.2819 -0.1579 -0.1815\n",
            "H-0\t-0.7276960611343384\tDites @-@ moi votre nom et un peu de vous .\n",
            "D-0\t-0.7276960611343384\tDites-moi votre nom et un peu de vous.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -2.0434 -0.1872\n",
            "H-0\t-0.793375551700592\tDites @-@ moi votre nom et un peu sur vous .\n",
            "D-0\t-0.793375551700592\tDites-moi votre nom et un peu sur vous.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -3.4049 -0.3754 -1.1687 -0.1849\n",
            "H-0\t-0.8001118898391724\tVeuillez me dire votre nom et un peu sur vous .\n",
            "D-0\t-0.8001118898391724\tVeuillez me dire votre nom et un peu sur vous.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -2.3226 -0.2832 -1.0518 -0.1854\n",
            "2022-05-17 07:01:03 | INFO | fairseq_cli.interactive | Total time: 14.336 seconds; translation time: 2.363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  beams_buf = indices_buf // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHbfXbxgL2xc"
      },
      "source": [
        "This generation script produces three types of outputs: a line prefixed with O is a copy of the original source sentence; H is the hypothesis along with an average log-likelihood; and P is the positional score per token position, including the end-of-sentence marker which is omitted from the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhX7jS6sGG9G",
        "outputId": "aa01740e-b412-40df-deb5-3537c57d753f"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --beam 100 --nbest 5 --source-lang en --target-lang fr --remove-bpe "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-17 07:01:20 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=100, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2022-05-17 07:01:20 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2022-05-17 07:01:20 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2022-05-17 07:01:20 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2022-05-17 07:01:30 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-05-17 07:01:30 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t9.321\tseconds\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -0.9387 -0.7073 -0.2819 -0.1579 -0.1815\n",
            "H-0\t-0.7244848012924194\tDites @-@ moi votre nom et un peu sur vous @-@ même .\n",
            "D-0\t-0.7244848012924194\tDites-moi votre nom et un peu sur vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -3.4049 -0.3754 -1.2054 -0.3654 -0.1554 -0.1808\n",
            "H-0\t-0.7276952862739563\tDites @-@ moi votre nom et un peu de vous .\n",
            "D-0\t-0.7276952862739563\tDites-moi votre nom et un peu de vous.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -2.0433 -0.1872\n",
            "H-0\t-0.7343103885650635\tDites @-@ moi votre nom et quelques mots sur vous @-@ même .\n",
            "D-0\t-0.7343103885650635\tDites-moi votre nom et quelques mots sur vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -2.1724 -2.0234 -0.7167 -0.4778 -0.8385 -0.4498 -0.1630 -0.1802\n",
            "2022-05-17 07:01:40 | INFO | fairseq_cli.interactive | Total time: 20.305 seconds; translation time: 9.321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  beams_buf = indices_buf // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeoSHSx8Y7ki"
      },
      "source": [
        "Diverse beam search produces much more varied generation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKRgFTN8QtV9",
        "outputId": "79f4e04d-4b4e-41cc-90a5-90341f4381a7"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --beam 5 --nbest 5 --source-lang en --target-lang fr --remove-bpe --diverse-beam-groups 5 --diverse-beam-strength 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-17 07:01:42 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=5, diverse_beam_strength=10.0, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2022-05-17 07:01:42 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2022-05-17 07:01:42 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2022-05-17 07:01:42 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2022-05-17 07:01:52 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-05-17 07:01:52 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.553\tseconds\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-1.8039686679840088\tMerci de me dire ton prénom et un peu de toi .\n",
            "D-0\t-1.8039686679840088\tMerci de me dire ton prénom et un peu de toi.\n",
            "P-0\t-4.9458 -0.2245 -0.3576 -1.1888 -4.5186 -9.0919 -0.0152 -0.3292 -1.2532 -0.2600 -0.4751 -1.0977 -1.3169 -0.1812\n",
            "H-0\t-1.932053804397583\tParlez de votre nom et de vos commentaires .\n",
            "D-0\t-1.932053804397583\tParlez de votre nom et de vos commentaires.\n",
            "P-0\t-4.4182 -0.1850 -6.1575 -1.2460 -0.3455 -0.2942 -1.2999 -1.9015 -4.5389 -0.6827 -0.1833\n",
            "H-0\t-2.4697072505950928\tDites @-@ moi votre nom et un peu de votre personne ! ... ?\n",
            "D-0\t-2.4697072505950928\tDites-moi votre nom et un peu de votre personne !... ?\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -3.2302 -2.5714 -6.6439 -12.8658 -8.1906 -0.3139\n",
            "H-0\t-2.8107852935791016\tFaites @-@ nous part de votre identité .\n",
            "D-0\t-2.8107852935791016\tFaites-nous part de votre identité.\n",
            "P-0\t-6.3486 -0.2764 -6.6879 -0.5047 -0.1712 -0.5412 -6.4277 -4.0507 -0.2888\n",
            "2022-05-17 07:01:55 | INFO | fairseq_cli.interactive | Total time: 13.363 seconds; translation time: 2.553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  beams_buf = indices_buf // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2KKChN1i8rO"
      },
      "source": [
        "Let's try using different decoding methods for generation and see what results we get!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVB2NqLTxRdz",
        "outputId": "042eb19a-19d9-4dbb-e1b1-d20c971a1fc3"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --sampling --sampling-topk 10 --nbest 5 --source-lang en --target-lang fr --remove-bpe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-17 07:01:57 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=True, sampling_topk=10, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2022-05-17 07:01:57 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2022-05-17 07:01:57 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2022-05-17 07:01:57 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2022-05-17 07:02:08 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-05-17 07:02:08 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.601\tseconds\n",
            "H-0\t-1.0527796745300293\tParlez @-@ moi de votre nom et de votre personne .\n",
            "D-0\t-1.0527796745300293\tParlez-moi de votre nom et de votre personne.\n",
            "P-0\t-4.4182 -0.1850 -0.1128 -0.1384 -0.5004 -0.4837 -0.2584 -0.2395 -1.2135 -2.0609 -3.5716 -0.3204 -0.1834\n",
            "H-0\t-1.287907600402832\tVeuillez me donner vos nom et un peu de vous @-@ même .\n",
            "D-0\t-1.287907600402832\tVeuillez me donner vos nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -2.8707 -4.1290 -2.0628 -0.2221 -1.8097 -0.3798 -0.6341 -1.4104 -0.7302 -0.2889 -0.1687 -0.1817\n",
            "H-0\t-1.373555064201355\tVeuillez me dire votre nom et un peu de vos propres yeux .\n",
            "D-0\t-1.373555064201355\tVeuillez me dire votre nom et un peu de vos propres yeux.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -5.1806 -3.5444 -3.6307 -0.1654 -0.1817\n",
            "H-0\t-1.6016371250152588\tVeuillez me dire votre nom en plus de vous parler .\n",
            "D-0\t-1.6016371250152588\tVeuillez me dire votre nom en plus de vous parler.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -9.0059 -1.0946 -0.6445 -1.0034 -0.8197 -1.8424 -0.1834\n",
            "H-0\t-1.813172459602356\tFaites @-@ moi part de votre adresse , de votre nom et de votre personnalité .\n",
            "D-0\t-1.813172459602356\tFaites-moi part de votre adresse, de votre nom et de votre personnalité.\n",
            "P-0\t-6.3486 -0.2764 -0.1921 -0.8476 -0.1666 -0.4705 -8.7628 -4.8857 -2.3746 -0.6913 -0.9729 -0.4558 -0.2187 -0.9814 -2.7996 -0.2010 -0.1784\n",
            "2022-05-17 07:02:11 | INFO | fairseq_cli.interactive | Total time: 13.571 seconds; translation time: 2.601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXWhc_LA36ph",
        "outputId": "35a7d7ce-08b7-436c-cbfb-a0c92f24829a"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --sampling --sampling-topp 0.1 --nbest 5 --source-lang en --target-lang fr --remove-bpe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-17 07:02:12 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=True, sampling_topk=-1, sampling_topp=0.1, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2022-05-17 07:02:12 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2022-05-17 07:02:12 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2022-05-17 07:02:12 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2022-05-17 07:02:23 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-05-17 07:02:23 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.643\tseconds\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "2022-05-17 07:02:26 | INFO | fairseq_cli.interactive | Total time: 13.390 seconds; translation time: 2.643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5exFgO8N3-Wt",
        "outputId": "b3afca46-7a57-480a-c5bc-9bec548424e8"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes  \\\n",
        "    --sampling --sampling-topp 0.5 --nbest 5 --source-lang en --target-lang fr --remove-bpe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-17 07:02:27 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=True, sampling_topk=-1, sampling_topp=0.5, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2022-05-17 07:02:27 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2022-05-17 07:02:27 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2022-05-17 07:02:27 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2022-05-17 07:02:38 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-05-17 07:02:38 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.760\tseconds\n",
            "H-0\t-0.5719991326332092\tDites @-@ moi votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.5719991326332092\tDites-moi votre nom et un peu de vous-même.\n",
            "P-0\t-2.0572 -0.3334 -0.1222 -0.1323 -0.8462 -0.2220 -0.2794 -0.9217 -0.2654 -0.5195 -1.5301 -0.6950 -0.3036 -0.1695 -0.1824\n",
            "H-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -0.9387 -0.7073 -0.2819 -0.1579 -0.1815\n",
            "H-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -0.9387 -0.7073 -0.2819 -0.1579 -0.1815\n",
            "H-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.6281494498252869\tVeuillez me dire votre nom et un peu de vous-même.\n",
            "P-0\t-2.7564 -0.3864 -0.8797 -0.4312 -0.1721 -0.3034 -0.6297 -0.1994 -0.7686 -0.9387 -0.7073 -0.2819 -0.1579 -0.1815\n",
            "H-0\t-0.7798036336898804\tMerci de me dire votre nom et un peu de vous @-@ même .\n",
            "D-0\t-0.7798036336898804\tMerci de me dire votre nom et un peu de vous-même.\n",
            "P-0\t-4.9458 -0.2245 -0.3576 -1.1888 -0.4086 -0.1679 -0.2633 -0.5277 -0.2001 -0.9251 -0.9691 -0.8695 -0.3117 -0.1560 -0.1813\n",
            "2022-05-17 07:02:41 | INFO | fairseq_cli.interactive | Total time: 14.145 seconds; translation time: 2.760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_XJCM-g4QIM",
        "outputId": "e2ee3a11-754c-4f46-c95b-f333c3a36c0c"
      },
      "source": [
        "%%bash\n",
        "MODEL_DIR=wmt14.en-fr.fconv-py\n",
        "echo \"Please tell me your name and a little about yourself .\" | fairseq-interactive \\\n",
        "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
        "    --tokenizer moses --bpe subword_nmt --bpe-codes $MODEL_DIR/bpecodes \\\n",
        "    --sampling --sampling-topp 0.9 --nbest 5 --source-lang en --target-lang fr --remove-bpe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-17 07:02:43 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe='subword_nmt', bpe_codes='wmt14.en-fr.fconv-py/bpecodes', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='wmt14.en-fr.fconv-py', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=5, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='wmt14.en-fr.fconv-py/model.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe='@@ ', replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=True, sampling_topk=-1, sampling_topp=0.9, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', target_lang='fr', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer='moses', tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2022-05-17 07:02:43 | INFO | fairseq.tasks.translation | [en] dictionary: 43771 types\n",
            "2022-05-17 07:02:43 | INFO | fairseq.tasks.translation | [fr] dictionary: 43807 types\n",
            "2022-05-17 07:02:43 | INFO | fairseq_cli.interactive | loading model(s) from wmt14.en-fr.fconv-py/model.pt\n",
            "2022-05-17 07:02:54 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-05-17 07:02:54 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\tPlease tell me your name and a little about yourself .\n",
            "W-0\t2.600\tseconds\n",
            "H-0\t-1.5681943893432617\tParlez @-@ moi brièvement de votre nom et vous @-@ même .\n",
            "D-0\t-1.5681943893432617\tParlez-moi brièvement de votre nom et vous-même.\n",
            "P-0\t-4.4182 -0.1850 -0.1128 -0.1384 -8.5462 -0.1935 -0.9205 -0.4523 -0.4186 -5.3293 -0.6749 -0.1980 -0.1853 -0.1818\n",
            "H-0\t-1.5689349174499512\tMerci de me trouver votre nom et un peu de vous @-@ même .\n",
            "D-0\t-1.5689349174499512\tMerci de me trouver votre nom et un peu de vous-même.\n",
            "P-0\t-4.9458 -0.2245 -0.3576 -11.3675 -0.7290 -0.2468 -0.3511 -1.2775 -0.3742 -0.5430 -1.6439 -0.8327 -0.2829 -0.1766 -0.1810\n",
            "H-0\t-1.937212586402893\tPour tout renseignement sur vous , dites @-@ moi votre nom .\n",
            "D-0\t-1.937212586402893\tPour tout renseignement sur vous, dites-moi votre nom.\n",
            "P-0\t-7.3289 -6.2315 -1.8031 -1.5807 -2.4611 -1.0810 -2.4481 -0.1704 -0.2198 -0.9769 -0.2064 -0.4911 -0.1848\n",
            "H-0\t-3.177128314971924\tContentez @-@ vous de se méfier de vous .\n",
            "D-0\t-3.177128314971924\tContentez-vous de se méfier de vous.\n",
            "P-0\t-14.8833 -0.1597 -0.1674 -0.1900 -0.7624 -0.5936 -9.5638 -11.0476 -0.6289 -0.8480 -1.5394 -0.7348 -0.1838\n",
            "H-0\t-3.216749429702759\tMerci de me faire part une petite citation de vous .\n",
            "D-0\t-3.216749429702759\tMerci de me faire part une petite citation de vous.\n",
            "P-0\t-4.9458 -0.2245 -0.3576 -5.1416 -0.6023 -12.0627 -1.3743 -8.9528 -1.0531 -2.1262 -1.5769 -0.1831\n",
            "2022-05-17 07:02:57 | INFO | fairseq_cli.interactive | Total time: 13.619 seconds; translation time: 2.600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97H-8SMqYgQN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}