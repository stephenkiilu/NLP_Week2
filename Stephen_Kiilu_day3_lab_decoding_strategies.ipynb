{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenkiilu/NLP_Week2/blob/main/Stephen_Kiilu_day3_lab_decoding_strategies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T61Hd1w7XQ8"
      },
      "source": [
        "# Lab 3: Decoding Algorithms in Natural Language Processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnOhgsYa9jFG"
      },
      "source": [
        "# Review:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGY2h43gNyqt"
      },
      "source": [
        "\n",
        "## Language modeling:\n",
        "\n",
        "* Setup:\n",
        "  * $Y = (y_1,y_2,\\dots,y_T)$, where $y_t \\in \\mathcal{V}$ with $\\mathcal{V}$ a set of all unique tokens.\n",
        "  * The sequence length $T \\in \\{1,2,3,\\dots\\}$ may vary from one sequence to another.\n",
        "  * $\\mathcal{V}$ includes a special symbol $\\langle eos \\rangle$ as well as a few other ones such as $\\langle bos \\rangle$, $\\langle unk \\rangle$, etc.\n",
        "  * $y_T = \\langle eos \\rangle$ for any $Y$.\n",
        "\n",
        "* Goal:\n",
        "  * Build a model (parametrized by $\\theta$) that computes a probability $p_\\theta (Y)$.\n",
        "  * A reasonable $Y$ receives a high probability (according to our training distribution).\n",
        "\n",
        "`GPT-2` demo the lab session in day 1 was a perfect example of this (although we used it in a conditional language model in a sentence completion task)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwLa8cWC9cDY"
      },
      "source": [
        "## Conditional language modeling:\n",
        "\n",
        "$$\n",
        "\\hat{Y} = \\underset{Y\\in\\mathcal{Y}}{\\arg\\max} \\log p_\\theta (Y\\mid X),\\quad \\text{where}\n",
        "$$\n",
        "* $X$ is the context (source sentence in machine translation).\n",
        "* $\\hat{Y}$ is the target sentence that our model generates.\n",
        "\n",
        "We explored this in depth in the context of machine translation in day 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5RG5Hxi9-6Y"
      },
      "source": [
        "# Contents:\n",
        "## Review of materials from day 1 & 2 (10 mins)\n",
        "## Part 1: Decoding Algorithm Fundamentals (1 hour)\n",
        "1. Greedy decoding\n",
        "2. Beam search\n",
        "3. Ancestral sampling\n",
        "4. Top-$k$ sampling\n",
        "5. Necleus (top-$p$) sampling\n",
        "\n",
        "## Intermission (10 minutes)\n",
        "\n",
        "## Part 2: Curses of Approximate Decoding Algorithms (30 minutes)\n",
        "* Infinitely long sequences\n",
        "* Premature sequences\n",
        "* Hallucination\n",
        "\n",
        "## Q&A Session (10 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "upVNPtYxkesh"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/pytorch/fairseq.git &> /dev/null; cd fairseq; pip install . &> /dev/null; # fairseq setup\n",
        "! pip install sacremoses subword_nmt fastBPE sentencepiece bitarray &> /dev/null # tokenziers setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q2Gu_8FDgIye"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "import operator, math, pickle, os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G8agja8LjQI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e5ebd4-0c66-40ac-aa8a-663b96462ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OKPu0moBvDqW1R52Az2CVAE1dYtXqixK\n",
            "To: /content/model_best.pt\n",
            "100% 84.9M/84.9M [00:00<00:00, 121MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QkgivpD2cjHxZxg6diIgLaOpMbp4Kh7A\n",
            "To: /content/model_best_args.pkl\n",
            "100% 1.23k/1.23k [00:00<00:00, 2.11MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qsAAFVMjyp-HWno4WEy5S9EdxsK5VLj_\n",
            "To: /content/model_best_vocab.pkl\n",
            "100% 831k/831k [00:00<00:00, 96.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UG4h0HEMaWaloKLcC1zxMCpDR1e7RoES\n",
            "To: /content/utils.py\n",
            "100% 27.6k/27.6k [00:00<00:00, 30.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HNlwzSU8N3eX4vAxk36rmWZiBXYJDnsS\n",
            "To: /content/iwslt17fren.pt\n",
            "100% 663M/663M [00:04<00:00, 158MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XjoLni70BHSsFpo7snls1fjANVdxWj5x\n",
            "To: /content/dict.fr.txt\n",
            "100% 76.2k/76.2k [00:00<00:00, 75.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iNG7yVwHbVLEwFneeon9udwL5hAMwCz7\n",
            "To: /content/dict.en.txt\n",
            "100% 83.6k/83.6k [00:00<00:00, 65.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NbZyYDEcRAwTw0JVPxm7yjiyOR5Nkqgv\n",
            "To: /content/sentencepiece.bpe.model\n",
            "100% 480k/480k [00:00<00:00, 133MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WexFfEGS5fWRXEdtD0pn6h4GegtiWnhn\n",
            "To: /content/sentencepiece.bpe.vocab\n",
            "100% 215k/215k [00:00<00:00, 116MB/s]\n"
          ]
        }
      ],
      "source": [
        "# downloading LSTM LM trained on wikitext-2 -- for decoding code walkthrough\n",
        "\n",
        "! gdown https://drive.google.com/uc?id=1OKPu0moBvDqW1R52Az2CVAE1dYtXqixK # model\n",
        "! gdown https://drive.google.com/uc?id=1QkgivpD2cjHxZxg6diIgLaOpMbp4Kh7A # model args.\n",
        "! gdown https://drive.google.com/uc?id=1qsAAFVMjyp-HWno4WEy5S9EdxsK5VLj_ # vocab.\n",
        "! gdown https://drive.google.com/uc?id=1UG4h0HEMaWaloKLcC1zxMCpDR1e7RoES # utils\n",
        "\n",
        "\n",
        "# downloading the standard transformer model trained w/ IWSLT’17 FR-EN. -- for decoding demo\n",
        "\n",
        "! gdown https://drive.google.com/uc?id=1HNlwzSU8N3eX4vAxk36rmWZiBXYJDnsS # model (iwslt17fren.pt)\n",
        "! gdown https://drive.google.com/uc?id=1XjoLni70BHSsFpo7snls1fjANVdxWj5x # dict.fr.txt\n",
        "! gdown https://drive.google.com/uc?id=1iNG7yVwHbVLEwFneeon9udwL5hAMwCz7 # dict.en.txt\n",
        "! gdown https://drive.google.com/uc?id=1NbZyYDEcRAwTw0JVPxm7yjiyOR5Nkqgv # sentencepiece.bpe.model\n",
        "! gdown https://drive.google.com/uc?id=1WexFfEGS5fWRXEdtD0pn6h4GegtiWnhn # sentencepiece.bpe.vocab\n",
        "\n",
        "! mkdir /content/iwslt-data/\n",
        "! mv /content/dict.en.txt /content/iwslt-data/\n",
        "! mv /content/dict.fr.txt /content/iwslt-data/\n",
        "! mv /content/sentencepiece.bpe.model /content/iwslt-data/\n",
        "! mv /content/sentencepiece.bpe.vocab /content/iwslt-data/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model for decoding method walkthrough.\n",
        "class RNNLanguageModel(nn.Module):\n",
        "    def __init__(self, options):\n",
        "        super().__init__()\n",
        "        self.eos_idx = options[\"eos_idx\"]\n",
        "        self.drop = nn.Dropout(options[\"dropout\"])\n",
        "        self.lookup = nn.Embedding(\n",
        "            num_embeddings=options[\"num_embeddings\"],\n",
        "            embedding_dim=options[\"embedding_dim\"],\n",
        "            padding_idx=options[\"padding_idx\"],\n",
        "        )\n",
        "        self.rnn = eval(options[\"rnn_type\"])(\n",
        "            options[\"input_size\"],\n",
        "            options[\"hidden_size\"],\n",
        "            options[\"num_layers\"],\n",
        "            dropout=options[\"dropout\"],\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.projection = nn.Linear(options[\"hidden_size\"], options[\"output_dim\"])\n",
        "        if options[\"tie_weights\"]:\n",
        "            self.projection.weight = self.lookup.weight\n",
        "\n",
        "    def forward(self, encoded_input_sequence):\n",
        "        logits, _ = self.step(encoded_input_sequence, None)\n",
        "        return logits\n",
        "\n",
        "    def step(self, encoded_input_sequence, hidden):\n",
        "        embeddings = self.drop(self.lookup(encoded_input_sequence))\n",
        "        output, hidden = self.rnn(embeddings, hidden)\n",
        "        output = self.drop(output)\n",
        "        logits = self.projection(output)\n",
        "        return logits, hidden\n",
        "\n",
        "ckpt = torch.load(\"/content/model_best.pt\",map_location=torch.device(device))\n",
        "model_args = pickle.load(open(\"/content/model_best_args.pkl\", \"rb\"))\n",
        "vocab = pickle.load(open(\"/content/model_best_vocab.pkl\", \"rb\"))\n",
        "\n",
        "options = {**model_args.__dict__}\n",
        "options[\"padding_idx\"] = vocab.get_id('<pad>')\n",
        "options[\"eos_idx\"] = vocab.get_id('<eos>')\n",
        "options[\"num_embeddings\"] = options['dataset_stats']['vocab_size']\n",
        "options[\"output_dim\"] = options['dataset_stats']['vocab_size']\n",
        "options[\"input_size\"] = options['embedding_dim']\n",
        "options[\"num_layers\"] = 2\n",
        "\n",
        "model = RNNLanguageModel(options).to(device)\n",
        "model.load_state_dict(ckpt['model_dict'])"
      ],
      "metadata": {
        "id": "oC1fNCuJvgc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718c64a6-cb74-4310-9dbc-5316bec22366"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGMihQ4xCxke"
      },
      "source": [
        "# Part 1: Decoding Algorithms\n",
        "\n",
        "* For the line-by-line walkthrough of the decoding algorithms, we will use a 2-layer LSTM decoder trained on the `Wikitext-2` dataset for the sequence completion task, given a prefix as a context.\n",
        "* We will use a transformer-based machine translation system trained on the `IWSLT' 17` `FR-EN` datasets to see how these algorithms pair with a larger scale model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0lRdGSzvpG-"
      },
      "source": [
        "## 1.1) Deterministic Decoding Algorithms:\n",
        "Given a well-trained conditional language model, $p_\\theta$, and a context $X$, both greedy and beam search aim to tackle the following objective:\n",
        "\n",
        "$$\n",
        "Y^{MAP} = \\underset{Y\\in\\mathcal{Y}}{\\arg\\max} \\log p_\\theta (Y \\mid X)\n",
        "$$\n",
        "\n",
        "This is known as $maximum$ $a$ $posteriori$ ($MAP$) decoding since $p_\\theta$ is a probability model and the objective is to find the most-probable hypothesis among all candidate hypotheses.\n",
        "\n",
        "However, unfortunately, obtaining the optimal sequence requires an exact/exhaustive search over the hypothesis space, which is intractable. We will need to exhaustively enumerate all the possible output sequences with their conditional probabilities. Only then can we choose the output with the highest conditional probability.\n",
        "\n",
        "* What is the computational complexity of exact search?\n",
        "$$\n",
        "|\\mathcal{Y}| = \\mathcal{O}\\big({|\\mathcal{V}|}^{T}\\big)\n",
        "$$\n",
        "  * The size of the space of $\\mathcal{Y}$ (space of sequences) grows exponentially with respect to the length of the sequence. Hence, exact decoding is intractable.\n",
        "\n",
        "### This is why we *MUST* resort to approximate decoding.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We will learn about two approaches that tries to approximate the $MAP$ solution by taking a set hypotheses constructed by taking either:\n",
        "* a token assigned with the highest probability at each timestep (greedy)\n",
        "* a set of candidate hypotheses with the highest joint probability at each timestep (beam search)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTOcMNRJAKBt"
      },
      "source": [
        "### 1.1.1) Greedy Decoding:\n",
        "* Simply take the $\\max$ token according to the conditional distribution at each timestep. In other words, at each step, pick the most probable token.\n",
        "$$\n",
        "y_t = \\underset{y_t \\in \\mathcal{V}}{\\arg\\max} \\log p_\\theta (y_t \\mid y_{<t}, X)\n",
        "$$\n",
        "* Once $\\langle eos \\rangle$ token, a special token that marks the end of sequence generation, we stop our decoding process.\n",
        "\n",
        "* Unlike exhaustive search, greedy decoding only requires $\\mathcal{O}(|\\mathcal{V}|\\cdot T)$. The computational complexity of generating a sequence decreased from exponential to linear with respect to time.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*AQqxmtpfW8t7AgFJ0pFbdA.png\" width=\"500\" height=\"300\">\n",
        "\n",
        "* This can be a good baseline, but this method is inherently flawed: **the best token at the current step does not necessarily lead to the best sequence**.\n",
        "$$\n",
        "\\underset{Y}{\\max} \\prod_{t=1}^T  p_\\theta (y_t \\mid y_{<t},X) \\ne \\prod_{t=1}^T \\underset{y_t}{\\max} \\;p_\\theta (y_t \\mid y_{<t},X)\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global BOS_IDX\n",
        "global EOS_IDX\n",
        "global PAD_IDX\n",
        "global MAX_LENGTH\n",
        "\n",
        "BOS_IDX = vocab.get_id('<bos>')\n",
        "EOS_IDX = vocab.get_id('<eos>')\n",
        "PAD_IDX = vocab.get_id('<pad>')\n",
        "MAX_LENGTH = 50 # Wikitext-2 has a average sequence length of 23-24."
      ],
      "metadata": {
        "id": "XDTJKLDz2Eze"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model:nn.Module, prefix:str, vocab:object,) -> (torch.Tensor, torch.Tensor):\n",
        "    \"\"\"\n",
        "    Implements the greedy search algorithm for decoding the most likely continuation sequence given the prefix (context).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        Our model (2-layer LSTM trained on wikitext-2) which will generate the continuation of the given prefix.\n",
        "    prefix: str\n",
        "        A string of tokens given as a context. \n",
        "    vocab: object\n",
        "        A dictionary object for encoding tokens into corresponding indicies and vice-versa.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    (torch.Tensor, torch.Tensor): tuple\n",
        "        List of ``(predictions, log_probs)``, where ``predictions``\n",
        "        has shape ``(MAX_LENGTH)`` and ``log_probs``\n",
        "        has shape ``(MAX_LENGTH)``.        \n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    # set the max. generation length as MAX_LENGTH. use <pad> tokens as placeholders for the tensor to store the decoded tokens.\n",
        "    predictions = (torch.ones(MAX_LENGTH)*PAD_IDX).int()\n",
        "    log_probs = torch.zeros(MAX_LENGTH)\n",
        "    \n",
        "    # encode the prefix given as a string into integer indices corresponding to their indices in the vocab set.\n",
        "    decoder_input =  torch.tensor([[BOS_IDX]+vocab.encode_token_seq(prefix.split())],device=device)\n",
        "    decoder_hidden = None\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for t in range(MAX_LENGTH):\n",
        "            decoder_logits, decoder_hidden = model.step(decoder_input, decoder_hidden)\n",
        "            decoder_logits = decoder_logits[:,-1:,:] # selecting the last timestep (for encoding the prefix.)\n",
        "            \n",
        "            top_log_prob, top_vocab_idx = decoder_logits.log_softmax(-1).topk(1)  # get candidates; softmax added to compute joint lporb\n",
        "            \n",
        "            predictions[t] = top_vocab_idx.item()\n",
        "            log_probs[t] = top_log_prob.item()\n",
        "            \n",
        "            if top_vocab_idx.item() == EOS_IDX:\n",
        "                break    \n",
        "                \n",
        "            decoder_input = top_vocab_idx.squeeze(-1)\n",
        "            \n",
        "    return (predictions, log_probs)"
      ],
      "metadata": {
        "id": "mkNw5s0KZ2ur"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy(prefix:str):\n",
        "    predictions, log_probs = greedy_decode(model, prefix, vocab)\n",
        "    predictions = [token for token in vocab.decode_idx_seq(predictions.tolist()) if token != '<pad>']\n",
        "    predictions = \" \".join(token for token in predictions).strip()\n",
        "    log_probs = log_probs[log_probs.nonzero(as_tuple=True)[0]]\n",
        "    \n",
        "    print(f'\\n(Greedy Decoding Result):')\n",
        "    print(f' - (prefix)\\t\\t:\\t{prefix}')\n",
        "    print(f' - (continuation)\\t:\\t{predictions}')\n",
        "    print(f' - (log prob. of seq.)\\t:\\t{log_probs.sum():.5f}')"
      ],
      "metadata": {
        "id": "a5nIopM5kQGp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = '''While it retained the standard features of the series ,'''\n",
        "gt_cont = '''it also underwent multiple adjustments , such as making the game more <unk> for series newcomers '''\n",
        "\n",
        "print('''(Original Sentence):''')\n",
        "print(f' - (prefix)\\t\\t:\\t{prefix}')\n",
        "print(f' - (ground truth cont.)\\t:\\t{gt_cont}')\n",
        "\n",
        "greedy(prefix)"
      ],
      "metadata": {
        "id": "V71kQcQZ2dzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb15d10-1db1-4653-b13e-3d5c135501c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            " - (prefix)\t\t:\tWhile it retained the standard features of the series ,\n",
            " - (ground truth cont.)\t:\tit also underwent multiple adjustments , such as making the game more <unk> for series newcomers \n",
            "\n",
            "(Greedy Decoding Result):\n",
            " - (prefix)\t\t:\tWhile it retained the standard features of the series ,\n",
            " - (continuation)\t:\tthe song was released on the album . <eos>\n",
            " - (log prob. of seq.)\t:\t-14.64477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = '''Due to low sales of Valkyria Chronicles II , Valkyria'''\n",
        "gt_cont = '''Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 .'''\n",
        "\n",
        "print('''(Original Sentence):''')\n",
        "print(f' - (prefix)\\t\\t:\\t{prefix}')\n",
        "print(f' - (ground truth cont.)\\t:\\t{gt_cont}')\n",
        "\n",
        "greedy(prefix)"
      ],
      "metadata": {
        "id": "VWHZj9B_Wd7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3baa47-5203-43b2-9e49-e6d457267cf7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (ground truth cont.)\t:\tChronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 .\n",
            "\n",
            "(Greedy Decoding Result):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            " - (log prob. of seq.)\t:\t-15.18872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = '''Outside missions , the player characters rest in a camp'''\n",
        "gt_cont = ''', where units can be customized and character growth occurs .'''\n",
        "\n",
        "print('''(Original Sentence):''')\n",
        "print(f' - (prefix)\\t\\t:\\t{prefix}')\n",
        "print(f' - (ground truth cont.)\\t:\\t{gt_cont}')\n",
        "\n",
        "greedy(prefix)"
      ],
      "metadata": {
        "id": "UJ8vq0s6WgRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd860d9-e71e-4640-c4b8-74f1a03e25c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (ground truth cont.)\t:\t, where units can be customized and character growth occurs .\n",
            "\n",
            "(Greedy Decoding Result):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (continuation)\t:\t, and the player is able to make a new role in the game . <eos>\n",
            " - (log prob. of seq.)\t:\t-30.65266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = '''I am a student '''\n",
        "# gt_cont = ''', where units can be customized and character growth occurs .'''\n",
        "\n",
        "print('''(Original Sentence):''')\n",
        "print(f' - (prefix)\\t\\t:\\t{prefix}')\n",
        "# print(f' - (ground truth cont.)\\t:\\t{gt_cont}')\n",
        "\n",
        "greedy(prefix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp0D1eMxDbDV",
        "outputId": "6a65704d-38d6-428a-a445-e5cb46846937"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            " - (prefix)\t\t:\tI am a student \n",
            "\n",
            "(Greedy Decoding Result):\n",
            " - (prefix)\t\t:\tI am a student \n",
            " - (continuation)\t:\t, but I 'm not going to be a <unk> , but I 'm not going to be a bit of the <unk> . <eos>\n",
            " - (log prob. of seq.)\t:\t-43.88878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaiY1_agQV2N"
      },
      "source": [
        "This generation script using `fairseq` produces three types of outputs: \n",
        "* `S-` is the `Source sentence` the model has to translate\n",
        "* `T-` is the `Target` (or reference or \"gold\") sentence you provided for this source, the one you want to compare to. It's possible to run `fairseq-generate` without target sentences, in which case this line won't appear.\n",
        "* `H-` is the `tokenized Hypothesis` (or system) translation (i.e. the tokens generated by your model) along with its score. If your model works with sub-word tokens (ex: `BPE`), this line will be sub-words tokens, separated by spaces. Even if your model works with whole words but considers punctuation symbols as tokens, they will be space-separated. For example, you might obtain something like that with `BPE` and `Moses` tokenization.\n",
        "* `D-` is the same as `H-` but `Detokenized` (after applying `BPE` and word tokenization in reverse)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "koDxNwNYHcsF",
        "outputId": "6fc1cd2f-4538-4d5c-e051-1c77c7b77234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Je ▁m & ap os ; ▁appelle ▁E ug ène ▁. ▁C & ap os ; ▁est ▁un ▁plais ir ▁de ▁vous ▁rencont rer ▁tous ▁.\n",
            "W-0\t0.173\tseconds\n",
            "H-0\t-11.695178985595703\t▁I ' m ▁called ▁E ug ene . ▁That ' s ▁a ▁pleasure ▁to ▁meet ▁you ▁all .\n",
            "D-0\t-11.695178985595703\tI'm called Eugene. That's a pleasure to meet you all.\n",
            "P-0\t-0.4590 -0.4913 -0.0948 -1.6790 -0.0227 -0.0410 -0.8890 -0.6845 -2.2958 -0.9059 -0.1132 -0.5170 -1.2826 -0.2597 -0.1267 -1.3354 -0.1655 -0.2187 -0.1134\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Je m'appelle Eugène. C'est un plaisir de vous rencontrer tous.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.0 --max-len-b 200 \\\n",
        "    --beam 1 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DBEh-EI_HcsF",
        "outputId": "657f7c0e-f290-4fdc-b080-38a75fdad9ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁sal ut ▁mon ▁nom ▁est ▁ma x ▁, ▁je ▁suis ▁ass istant ▁d & ap os ; ▁enseign ement ▁pour ▁le ▁cours ▁de ▁ma î tr ise ▁af ric aine ▁en ▁P N L\n",
            "W-0\t0.239\tseconds\n",
            "H-0\t-29.869937896728516\t▁And ▁my ▁name ▁is ▁a ▁ma x , ▁and ▁I ' m ▁a ▁professor ▁of ▁la und ry ▁education ▁for ▁the ▁African ▁master y ▁course ▁in ▁P N L .\n",
            "D-0\t-29.869937896728516\tAnd my name is a max, and I'm a professor of laundry education for the African mastery course in PNL.\n",
            "P-0\t-2.1503 -0.6402 -0.0393 -0.4528 -1.8780 -1.0858 -0.0335 -0.8115 -0.4287 -0.2614 -0.4921 -0.0519 -0.5928 -3.4629 -1.2959 -5.0801 -1.2235 -0.5169 -2.1784 -0.9163 -0.8905 -1.7086 -0.4194 -1.0711 -0.6196 -0.3397 -0.0649 -0.0536 -0.9041 -0.0941 -0.1117\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"salut mon nom est max, je suis assistant d'enseignement pour le cours de maîtrise africaine en PNL\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.0 --max-len-b 200 \\\n",
        "    --beam 1 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Bonjour, je m'appelle Stephen Kiilu. Je suis étudiant à AIMS Sénégal.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.0 --max-len-b 200 \\\n",
        "    --beam 1 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVQoxvAHFg6c",
        "outputId": "c11a4984-cf49-4ddd-c594-3d88bb0404b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Bon jour ▁, ▁je ▁m & ap os ; ▁appelle ▁Step hen ▁K i il u ▁. ▁Je ▁suis ▁étud iant ▁à ▁A I MS ▁S én ég al ▁.\n",
            "W-0\t0.253\tseconds\n",
            "H-0\t-10.756360054016113\t▁H ell o , ▁I ' m ▁m ap os ; ▁Step hen ▁K i il u . ▁I ' m ▁a ▁student ▁at ▁A I MS ▁S ene gal .\n",
            "D-0\t-10.756360054016113\tHello, I'm mapos; Stephen Kiilu. I'm a student at AIMS Senegal.\n",
            "P-0\t-0.3531 -0.5659 -0.0138 -0.3345 -0.2247 -0.8498 -0.0724 -2.1625 -1.2037 -0.1183 -0.2667 -0.4159 -0.0093 -0.0212 -0.1306 -0.0474 -0.0097 -2.0752 -0.2214 -0.1957 -0.0483 -0.1106 -0.1980 -0.2362 -0.0917 -0.0668 -0.0537 -0.1731 -0.1155 -0.1313 -0.1252 -0.1140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"what do I love most? Studying and traveling.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.0 --max-len-b 200 \\\n",
        "    --beam 1 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOZx7z90GJ53",
        "outputId": "82233057-a671-493e-af8e-64683a3759d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t<unk> ▁do ▁I ▁love ▁most ▁? ▁Stud ying ▁and <unk> ▁.\n",
            "W-0\t0.116\tseconds\n",
            "H-0\t-16.332529067993164\t▁Can ▁I ▁have ▁a ▁lot ▁of ▁fun ? ▁Stud ent ▁and ▁Wikipedia .\n",
            "D-0\t-16.332529067993164\tCan I have a lot of fun? Student and Wikipedia.\n",
            "P-0\t-1.7860 -0.0906 -1.5343 -1.8780 -2.1665 -0.0934 -0.9180 -0.3800 -0.0071 -1.6240 -0.1594 -5.3911 -0.1927 -0.1114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccEbdE9OONF5"
      },
      "source": [
        "### 1.1.2) Beam Search:\n",
        "A $de$ $facto$ standard decoding algorithm in many NLP areas that requires exact search, such as machine translation, open generative question and answering (open-domain dialogue generation), etc.\n",
        "\n",
        "Beam search is a *deterministic decoding algorithm* and improves upon the greedy decoding strategy by maintaining $K$-hypotheses at each time step, instead of a single one. Let\n",
        "\n",
        "$$\n",
        "\\mathcal{H}_{t-1} = \\bigg\\{\\big(\\tilde{x}_1^1,\\tilde{x}_2^1,\\dots,\\tilde{x}_{t-1}^1\\big),\\big(\\tilde{x}_1^2,\\tilde{x}_2^2,\\dots,\\tilde{x}_{t-1}^2\\big),\\dots, ,\\big(\\tilde{x}_1^K,\\tilde{x}_2^K,\\dots,\\tilde{x}_{t-1}^K\\big)\\bigg\\}\n",
        "$$\n",
        "\n",
        "be a set of current hypotheses at time $t$. Then, from each current hypothesis the following candidate hypotheses are generated:\n",
        "$$\n",
        "\\mathcal{H}_{t}^k = \\bigg\\{\\big(\\tilde{x}_1^k,\\tilde{x}_2^k,\\dots,\\tilde{x}_{t-1}^k,v_1\\big),\\big(\\tilde{x}_1^k,\\tilde{x}_2^k,\\dots,\\tilde{x}_{t-1}^k,v_2\\big),\\dots,\\big(\\tilde{x}_1^k,\\tilde{x}_2^k,\\dots,\\tilde{x}_{t-1}^k,v_{|\\mathcal{V}|}\\big)\\bigg\\}\n",
        "$$\n",
        "\n",
        "where $v_j$ denotes the $j$-th symbols in the vocabulary $\\mathcal{V}$.\n",
        "\n",
        "The top-$K$ hypotheses from the union of all such hypotheses sets $\\mathcal{H}_t^k,$ where $k=1,2,\\dots,K$, are selected baseed on their scores (usually the log probability of a sequence).\n",
        "\n",
        "$$\n",
        "\\mathcal{H}_t = \\cup_{k=1}^K\\mathcal{B}_k,\\quad\\text{where}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathcal{B}_k = \\underset{\\tilde{X}\\in\\mathcal{A}_k}{arg\\max}\\log p_\\theta (\\tilde{X}\\mid Y), \\mathcal{A}_k = \\mathcal{A}_{k-1} - \\mathcal{B}_{k-1}, \\text{ and } \\mathcal{A}_1 = \\cup_{k'=1}^K\\mathcal{H}_t^{k'}.\n",
        "$$\n",
        "\n",
        "In other words, beam search is a pruned version of breadth-first search which maintains an active set of $K$ partial translations. The computational complexity is $\\mathcal{O}(K\\cdot |\\mathcal{V}|\\cdot T)$.\n",
        "\n",
        "* Why is this better than the greedy decoding?\n",
        "  * Beam search reduces the risk of missing hidden high probability word sequences by keeping the most likely $K$ hypotheses at each time step and eventually choosing the hypothesis that has the overall highest probability.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "30Bjbr-hN5go",
        "outputId": "f053097c-e88b-470d-b8ad-7154894f07b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=1080 controls>\n",
              "      <source src=\"https://lena-voita.github.io/resources/lectures/seq2seq/general/beam_search.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "data_url = \"https://lena-voita.github.io/resources/lectures/seq2seq/general/beam_search.mp4\"\n",
        "HTML(\"\"\"\n",
        "<video width=1080 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qCdCNd09Nso6"
      },
      "outputs": [],
      "source": [
        "class BeamSearchNode(object):\n",
        "    def __init__(self, \n",
        "                 hidden_state:tuple, \n",
        "                 prev_node:object, \n",
        "                 token_idx:int, \n",
        "                 log_prob:float, \n",
        "                 length:int):\n",
        "        self.hidden_state = hidden_state\n",
        "        self.prev_node = prev_node\n",
        "        self.token_idx = token_idx\n",
        "        self.log_prob = log_prob\n",
        "        self.length = length\n",
        "\n",
        "    def get_score(self, alpha:float=1.0, reward:float=0.0, use_log_prob:bool=True):\n",
        "        # Add here a function for shaping a reward\n",
        "        return self.log_prob if use_log_prob else self.log_prob / float(self.length - 1 + 1e-6) + alpha * reward"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Beam search w/ DFS Style Implementation:"
      ],
      "metadata": {
        "id": "iMOyeRaP1-Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from queue import PriorityQueue\n",
        "\n",
        "def beam_search_decode(model:nn.Module, prefix:str, vocab:object, beam_size:int=3, n_best:int=1,) -> (torch.Tensor, torch.Tensor):\n",
        "    \"\"\"\n",
        "    Implements the beam search algorithm for decoding the most likely sequence given the prefix.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        Our model (2-layer LSTM trained on wikitext-2) which will generate the continuation of the given prefix.\n",
        "    prefix: str\n",
        "        A string of tokens given as a context. \n",
        "    vocab: object\n",
        "        A dictionary object for encoding tokens into corresponding indicies and vice-versa.\n",
        "    beam_size: int\n",
        "        The number of hypothesis to maintain at each time step.\n",
        "    n_best: int\n",
        "        The number of sentence to return at the end of search.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    (torch.Tensor, torch.Tensor): tuple\n",
        "        List of ``(predictions, log_probs)``, where ``predictions``\n",
        "        has shape ``(n_best, MAX_LENGTH)`` and ``log_probs``\n",
        "        has shape ``(n_best, MAX_LENGTH)``.        \n",
        "    \"\"\"\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # Encode the prefix given as a string into integer indices corresponding to their indices in the vocab set.\n",
        "    prefix_idx = vocab.encode_token_seq(prefix.split())\n",
        "    prefix_input =  torch.tensor([[BOS_IDX]+prefix_idx[:-1]], device=device)\n",
        "    \n",
        "    decoder_hidden = None\n",
        "    decoded_batch = []\n",
        "    decoder_input = torch.tensor([[prefix_idx[-1]]], device=device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        decoder_logits, decoder_hidden = model.step(prefix_input, decoder_hidden)\n",
        "        \n",
        "        # List for storing the <eos> beam nodes of K-best hypotheses found by the beam search.\n",
        "        eos_nodes = []\n",
        "        \n",
        "        # Beginning beam search node: hidden state vector, previous node, token id, log prob., length idx.\n",
        "        beam_node = BeamSearchNode(decoder_hidden, None, decoder_input, 0.0, 0)\n",
        "        beam_nodes_queue = PriorityQueue()\n",
        "        \n",
        "        # Start the queue : priority queue is a min. heap.\n",
        "        beam_nodes_queue.put((-beam_node.get_score(), beam_node))\n",
        "        \n",
        "        # ---- Start beam search. ---- #\n",
        "        while True:\n",
        "            # fetch the best node\n",
        "            cur_beam_score, cur_beam_node = beam_nodes_queue.get()\n",
        "            decoder_input = cur_beam_node.token_idx\n",
        "            decoder_hidden = cur_beam_node.hidden_state\n",
        "            \n",
        "            if decoder_input.item() == EOS_IDX and cur_beam_node.prev_node != None:\n",
        "                eos_nodes.append((cur_beam_score, cur_beam_node))\n",
        "                \n",
        "                # if we reached maximum # of sentences required\n",
        "                if len(eos_nodes) >= n_best:\n",
        "                    break\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "            # Decode for a single step using decoder.\n",
        "            decoder_logits, decoder_hidden = model.step(decoder_input, decoder_hidden)\n",
        "            \n",
        "            # PUT HERE REAL BEAM SEARCH OF\n",
        "            log_probs, vocab_indexes = decoder_logits.log_softmax(-1).topk(beam_size)\n",
        "            \n",
        "            for new_hypothesis in range(beam_size):\n",
        "                decoded_token = vocab_indexes[...,new_hypothesis]\n",
        "                log_prob = log_probs[...,new_hypothesis].item()\n",
        "                new_beam_node = BeamSearchNode(decoder_hidden, \n",
        "                                               cur_beam_node, \n",
        "                                               decoded_token, \n",
        "                                               cur_beam_node.log_prob + log_prob, \n",
        "                                               cur_beam_node.length + 1)\n",
        "                new_node_score = -new_beam_node.get_score() # We are using a min. heap., we negate the scores.\n",
        "                # put them into queue\n",
        "                beam_nodes_queue.put((new_node_score, new_beam_node))\n",
        "        # ---- End of the beam search. ---- #\n",
        "\n",
        "        # Set the max. generation length as MAX_LENGTH.\n",
        "        predictions = (torch.ones(n_best, MAX_LENGTH)*PAD_IDX).int() # Use <pad> tokens as placeholders.\n",
        "        log_probs = torch.zeros(n_best, MAX_LENGTH)\n",
        "        \n",
        "        for hyp_idx, (node_score, beam_node) in enumerate(sorted(eos_nodes, key=operator.itemgetter(0))):\n",
        "            predictions[hyp_idx,beam_node.length] = beam_node.token_idx\n",
        "            log_probs[hyp_idx,beam_node.length] = beam_node.log_prob\n",
        "            # back trace\n",
        "            while True:\n",
        "                beam_node = beam_node.prev_node\n",
        "                predictions[hyp_idx,beam_node.length] = beam_node.token_idx\n",
        "                log_probs[hyp_idx,beam_node.length] = beam_node.log_prob\n",
        "                if beam_node.prev_node == None:\n",
        "                    break\n",
        "    return (predictions, log_probs)"
      ],
      "metadata": {
        "id": "mtqbaJvkoqhG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search(prefix:str,beam_size:int=3,n_best:int=1):\n",
        "    assert 1 <= beam_size, \"Beam size needs to be greater than 1.\"\n",
        "    assert 1 <= n_best, \"n_best needs to be greater than 1.\"\n",
        "    assert n_best <= beam_size,\"Beam size needs to be greater than n_best.\"\n",
        "    \n",
        "    predictions, log_probs = beam_search_decode(model, prefix, vocab, beam_size, n_best)\n",
        "    \n",
        "    print(f'\\n(Beam Search w/ beam size = {beam_size} results):')\n",
        "    print(f' -  (prefix)\\t\\t:\\t{prefix}')\n",
        "    for best_idx in range(n_best):\n",
        "        prediction = [token for token in vocab.decode_idx_seq(predictions[best_idx,:].tolist()[1:]) if token != '<pad>']\n",
        "        prediction = \" \".join(token for token in prediction).strip()\n",
        "        log_prob = log_probs[best_idx,:]\n",
        "        log_prob = log_prob[log_prob.nonzero(as_tuple=True)[0]]\n",
        "        print(f'\\n {best_idx+1}. (continuation)\\t:\\t{prediction}')\n",
        "        print(f'    (joint log prob.)\\t:\\t{log_prob[-1]:.5f}')"
      ],
      "metadata": {
        "id": "cd1gTR9sdkR_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = '''Due to low sales of Valkyria Chronicles II , Valkyria'''\n",
        "gt_cont = '''Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 .'''\n",
        "\n",
        "print('''(Original Sentence):''')\n",
        "print(f' - (prefix)\\t\\t:\\t{prefix}')\n",
        "print(f' - (ground truth cont.)\\t:\\t{gt_cont}')\n",
        "\n",
        "greedy(prefix)\n",
        "beam_search(prefix, beam_size=1, n_best=1)\n",
        "beam_search(prefix, beam_size=2, n_best=2)\n",
        "beam_search(prefix, beam_size=3, n_best=3)\n",
        "beam_search(prefix, beam_size=4, n_best=4)\n",
        "beam_search(prefix, beam_size=5, n_best=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPgK3DsJ238a",
        "outputId": "86ff7622-ee2e-4cf2-910d-98e5c09ab6e0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (ground truth cont.)\t:\tChronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 .\n",
            "\n",
            "(Greedy Decoding Result):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            " - (log prob. of seq.)\t:\t-15.18872\n",
            "\n",
            "(Beam Search w/ beam size = 1 results):\n",
            " -  (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            "\n",
            " 1. (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            "    (joint log prob.)\t:\t-15.18872\n",
            "\n",
            "(Beam Search w/ beam size = 2 results):\n",
            " -  (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            "\n",
            " 1. (continuation)\t:\tChronicles III was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.09503\n",
            "\n",
            " 2. (continuation)\t:\tChronicles II was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.70081\n",
            "\n",
            "(Beam Search w/ beam size = 3 results):\n",
            " -  (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            "\n",
            " 1. (continuation)\t:\tChronicles : <eos>\n",
            "    (joint log prob.)\t:\t-6.38639\n",
            "\n",
            " 2. (continuation)\t:\tChronicles III was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.09503\n",
            "\n",
            " 3. (continuation)\t:\tChronicles II was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.70081\n",
            "\n",
            "(Beam Search w/ beam size = 4 results):\n",
            " -  (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            "\n",
            " 1. (continuation)\t:\tChronicles : <eos>\n",
            "    (joint log prob.)\t:\t-6.38639\n",
            "\n",
            " 2. (continuation)\t:\tChronicles III was not released . <eos>\n",
            "    (joint log prob.)\t:\t-8.55970\n",
            "\n",
            " 3. (continuation)\t:\tChronicles III was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.09503\n",
            "\n",
            " 4. (continuation)\t:\tChronicles II was not released . <eos>\n",
            "    (joint log prob.)\t:\t-9.13925\n",
            "\n",
            "(Beam Search w/ beam size = 5 results):\n",
            " -  (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            "\n",
            " 1. (continuation)\t:\tChronicles : <eos>\n",
            "    (joint log prob.)\t:\t-6.38639\n",
            "\n",
            " 2. (continuation)\t:\tChronicles III was not released . <eos>\n",
            "    (joint log prob.)\t:\t-8.55970\n",
            "\n",
            " 3. (continuation)\t:\tChronicles III was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.09503\n",
            "\n",
            " 4. (continuation)\t:\tChronicles II was not released . <eos>\n",
            "    (joint log prob.)\t:\t-9.13925\n",
            "\n",
            " 5. (continuation)\t:\tChronicles II was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.70081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = '''Outside missions , the player characters rest in a camp'''\n",
        "gt_cont = ''', where units can be customized and character growth occurs .'''\n",
        "\n",
        "print('''(Original Sentence):''')\n",
        "print(f' - (prefix)\\t\\t:\\t{prefix}')\n",
        "print(f' - (ground truth cont.)\\t:\\t{gt_cont}')\n",
        "\n",
        "greedy(prefix)\n",
        "beam_search(prefix, beam_size=1, n_best=1)\n",
        "beam_search(prefix, beam_size=2, n_best=2)\n",
        "beam_search(prefix, beam_size=3, n_best=3)\n",
        "beam_search(prefix, beam_size=4, n_best=4)\n",
        "beam_search(prefix, beam_size=5, n_best=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd3ik-F52335",
        "outputId": "3b69dc5d-94b9-4908-bf2c-94c38851260e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (ground truth cont.)\t:\t, where units can be customized and character growth occurs .\n",
            "\n",
            "(Greedy Decoding Result):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (continuation)\t:\t, and the player is able to make a new role in the game . <eos>\n",
            " - (log prob. of seq.)\t:\t-30.65266\n",
            "\n",
            "(Beam Search w/ beam size = 1 results):\n",
            " -  (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            "\n",
            " 1. (continuation)\t:\t, and the player is able to make a new role in the game . <eos>\n",
            "    (joint log prob.)\t:\t-30.65266\n",
            "\n",
            "(Beam Search w/ beam size = 2 results):\n",
            " -  (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            "\n",
            " 1. (continuation)\t:\t. <eos>\n",
            "    (joint log prob.)\t:\t-2.65808\n",
            "\n",
            " 2. (continuation)\t:\t. < <eos>\n",
            "    (joint log prob.)\t:\t-8.85676\n",
            "\n",
            "(Beam Search w/ beam size = 3 results):\n",
            " -  (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            "\n",
            " 1. (continuation)\t:\t. <eos>\n",
            "    (joint log prob.)\t:\t-2.65808\n",
            "\n",
            " 2. (continuation)\t:\t. < <eos>\n",
            "    (joint log prob.)\t:\t-8.85676\n",
            "\n",
            " 3. (continuation)\t:\tand a <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-10.55687\n",
            "\n",
            "(Beam Search w/ beam size = 4 results):\n",
            " -  (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            "\n",
            " 1. (continuation)\t:\t. <eos>\n",
            "    (joint log prob.)\t:\t-2.65808\n",
            "\n",
            " 2. (continuation)\t:\twith <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-8.43044\n",
            "\n",
            " 3. (continuation)\t:\t. < <eos>\n",
            "    (joint log prob.)\t:\t-8.85676\n",
            "\n",
            " 4. (continuation)\t:\tand <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-8.97778\n",
            "\n",
            "(Beam Search w/ beam size = 5 results):\n",
            " -  (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            "\n",
            " 1. (continuation)\t:\t. <eos>\n",
            "    (joint log prob.)\t:\t-2.65808\n",
            "\n",
            " 2. (continuation)\t:\twith <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-8.43044\n",
            "\n",
            " 3. (continuation)\t:\t. < <eos>\n",
            "    (joint log prob.)\t:\t-8.85676\n",
            "\n",
            " 4. (continuation)\t:\tand <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-8.97778\n",
            "\n",
            " 5. (continuation)\t:\twith a <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-9.09437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Beam search w/ BFS Style Implementation:"
      ],
      "metadata": {
        "id": "XKP6sjY5GFkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from queue import PriorityQueue\n",
        "\n",
        "def beam_search_decode_bfs(model:nn.Module, prefix:str, vocab:object, beam_size:int=3, n_best:int=1,) -> (torch.Tensor, torch.Tensor):\n",
        "    \"\"\"\n",
        "    Implements the beam search algorithm for decoding the most likely sequence given the prefix.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        Our model (2-layer LSTM trained on wikitext-2) which will generate the continuation of the given prefix.\n",
        "    prefix: str\n",
        "        A string of tokens given as a context. \n",
        "    vocab: object\n",
        "        A dictionary object for encoding tokens into corresponding indicies and vice-versa.\n",
        "    beam_size: int\n",
        "        The number of hypothesis to maintain at each time step.\n",
        "    n_best: int\n",
        "        The number of sentence to return at the end of search.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    (torch.Tensor, torch.Tensor): tuple\n",
        "        List of ``(predictions, log_probs)``, where ``predictions``\n",
        "        has shape ``(n_best, MAX_LENGTH)`` and ``log_probs``\n",
        "        has shape ``(n_best, MAX_LENGTH)``.        \n",
        "    \"\"\"\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # Encode the prefix given as a string into integer indices corresponding to their indices in the vocab set.\n",
        "    prefix_idx = vocab.encode_token_seq(prefix.split())\n",
        "    prefix_input = torch.tensor([[BOS_IDX]+prefix_idx], device=device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        decoder_logits, decoder_hidden = model.step(prefix_input, None)\n",
        "        \n",
        "        # List for storing the <eos> beam nodes of K-best hypotheses found by the beam search.\n",
        "        eos_nodes = []\n",
        "        \n",
        "        # Get top-K tokens by expanding the prefix.\n",
        "        log_probs, vocab_indexes = decoder_logits[:,-1:,:].log_softmax(-1).topk(beam_size)\n",
        "        \n",
        "        # Start the queue : priority queue (min. heap) that sorts the nodes by: \n",
        "        # (1.) timestep\n",
        "        # (2.) log-prob. of the seq.\n",
        "        beam_nodes_queue = PriorityQueue()\n",
        "        \n",
        "        for new_hyp in range(beam_size):\n",
        "            decoded_token = vocab_indexes[...,new_hyp]\n",
        "            log_prob = log_probs[...,new_hyp].item()\n",
        "            # Starting node of the beam search ::params:: (hidden_state_vector, prev_node, token_id, log_prob, timestep (length))\n",
        "            new_beam_node = BeamSearchNode(decoder_hidden, None, decoded_token, log_prob, 0)\n",
        "            # Put it into queue - we negate the score b.c. we are using a min. heap.\n",
        "            beam_nodes_queue.put(((0, -log_prob), new_beam_node))\n",
        "        \n",
        "        cur_timestep_nodes = 1\n",
        "        timestep = 0\n",
        "        # ---- Start beam search. ---- #\n",
        "        while True:\n",
        "            \n",
        "            # Removes all the non-selected hypothesis at each timestep.\n",
        "            if beam_size < cur_timestep_nodes:\n",
        "                while True:\n",
        "                    (node_timestep, _),_ = beam_nodes_queue.queue[0]\n",
        "                    if timestep == node_timestep:\n",
        "                        beam_nodes_queue.get()\n",
        "                    else:\n",
        "                        break\n",
        "                timestep += 1\n",
        "                cur_timestep_nodes = 1\n",
        "                \n",
        "            # Fetch the best node.\n",
        "            (cur_beam_timestep, cur_beam_score), cur_beam_node = beam_nodes_queue.get()\n",
        "            decoder_input = cur_beam_node.token_idx\n",
        "            decoder_hidden = cur_beam_node.hidden_state\n",
        "            \n",
        "            # avoid empty sequences.\n",
        "            if decoder_input.item() == EOS_IDX and cur_beam_node.prev_node != None:\n",
        "                eos_nodes.append(((cur_beam_timestep, cur_beam_score), cur_beam_node))\n",
        "                \n",
        "                # If we found K-many non-empty hypotheses, then end the search.\n",
        "                if len(eos_nodes) >= n_best:\n",
        "                    break\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "            # Decode for a single step using decoder.\n",
        "            decoder_logits, decoder_hidden = model.step(decoder_input, decoder_hidden)\n",
        "            \n",
        "            # Get top-K tokens from the current expansion.\n",
        "            log_probs, vocab_indexes = decoder_logits.log_softmax(-1).topk(beam_size)\n",
        "            \n",
        "            for new_hyp in range(beam_size):\n",
        "                decoded_token = vocab_indexes[...,new_hyp]\n",
        "                log_prob = log_probs[...,new_hyp].item()\n",
        "                new_beam_node = BeamSearchNode(decoder_hidden, \n",
        "                                               cur_beam_node, \n",
        "                                               decoded_token, \n",
        "                                               cur_beam_node.log_prob + log_prob, \n",
        "                                               cur_beam_node.length + 1)\n",
        "                # We are using a min. heap., so we negate the scores, and put nodes into the queue.\n",
        "                beam_nodes_queue.put(((new_beam_node.length, -new_beam_node.get_score()), new_beam_node))\n",
        "            cur_timestep_nodes += 1\n",
        "            \n",
        "        # ---- End of the beam search. ---- #\n",
        "        \n",
        "        # Set the max. generation length as MAX_LENGTH.\n",
        "        predictions = (torch.ones(n_best, MAX_LENGTH)*PAD_IDX).int() # Use <pad> tokens as placeholders.\n",
        "        log_probs = torch.zeros(n_best, MAX_LENGTH)\n",
        "        \n",
        "        for hyp_idx, ((node_length, node_score), beam_node) in enumerate(sorted(eos_nodes, key=operator.itemgetter(0))):\n",
        "            predictions[hyp_idx,beam_node.length] = beam_node.token_idx\n",
        "            log_probs[hyp_idx,beam_node.length] = beam_node.log_prob\n",
        "            # back trace\n",
        "            while True:\n",
        "                beam_node = beam_node.prev_node\n",
        "                predictions[hyp_idx,beam_node.length] = beam_node.token_idx\n",
        "                log_probs[hyp_idx,beam_node.length] = beam_node.log_prob\n",
        "                if beam_node.prev_node == None:\n",
        "                    break\n",
        "    return (predictions, log_probs)\n",
        "\n",
        "\n",
        "def beam_search_bfs(prefix:str,beam_size:int=3,n_best:int=1):\n",
        "    assert 1 <= beam_size, \"Beam size needs to be greater than 1.\"\n",
        "    assert 1 <= n_best, \"n_best needs to be greater than 1.\"\n",
        "    assert n_best <= beam_size,\"Beam size needs to be greater than n_best.\"\n",
        "    \n",
        "    predictions, log_probs = beam_search_decode_bfs(model, prefix, vocab, beam_size, n_best)\n",
        "    \n",
        "    print(f'\\n(Beam Search BFS w/ beam size = {beam_size} results):')\n",
        "    print(f' -  (prefix)\\t\\t:\\t{prefix}')\n",
        "    for best_idx in range(n_best):\n",
        "        prediction = [token for token in vocab.decode_idx_seq(predictions[best_idx,:].tolist()) if token != '<pad>']\n",
        "        prediction = \" \".join(token for token in prediction).strip()\n",
        "        log_prob = log_probs[best_idx,:]\n",
        "        log_prob = log_prob[log_prob.nonzero(as_tuple=True)[0]]\n",
        "        print(f'\\n {best_idx+1}. (continuation)\\t:\\t{prediction}')\n",
        "        print(f'    (joint log prob.)\\t:\\t{log_prob[-1]:.5f}')"
      ],
      "metadata": {
        "id": "9005kg7M94VI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = '''Due to low sales of Valkyria Chronicles II , Valkyria'''\n",
        "gt_cont = '''Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 .'''\n",
        "\n",
        "print('''(Original Sentence):''')\n",
        "print(f' - (prefix)\\t\\t:\\t{prefix}')\n",
        "print(f' - (ground truth cont.)\\t:\\t{gt_cont}')\n",
        "\n",
        "greedy(prefix)\n",
        "beam_search_bfs(prefix, beam_size=1, n_best=1)\n",
        "beam_search_bfs(prefix, beam_size=2, n_best=2)\n",
        "beam_search_bfs(prefix, beam_size=3, n_best=3)\n",
        "beam_search_bfs(prefix, beam_size=4, n_best=4)\n",
        "beam_search_bfs(prefix, beam_size=5, n_best=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8yJ_R0YVng2",
        "outputId": "3d3f3292-8775-48fe-942c-f1672cd1bf91"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (ground truth cont.)\t:\tChronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 .\n",
            "\n",
            "(Greedy Decoding Result):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            " - (log prob. of seq.)\t:\t-15.18872\n",
            "\n",
            "(Beam Search BFS w/ beam size = 1 results):\n",
            " -  (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            "\n",
            " 1. (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            "    (joint log prob.)\t:\t-15.18872\n",
            "\n",
            "(Beam Search BFS w/ beam size = 2 results):\n",
            " -  (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            "\n",
            " 1. (continuation)\t:\tChronicles III was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.09503\n",
            "\n",
            " 2. (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            "    (joint log prob.)\t:\t-15.18872\n",
            "\n",
            "(Beam Search BFS w/ beam size = 3 results):\n",
            " -  (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            "\n",
            " 1. (continuation)\t:\tChronicles III was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.09503\n",
            "\n",
            " 2. (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            "    (joint log prob.)\t:\t-15.18872\n",
            "\n",
            " 3. (continuation)\t:\tChronicles III was released in the United States on November 18 , 2012 . <eos>\n",
            "    (joint log prob.)\t:\t-15.19423\n",
            "\n",
            "(Beam Search BFS w/ beam size = 4 results):\n",
            " -  (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            "\n",
            " 1. (continuation)\t:\tChronicles III was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.09503\n",
            "\n",
            " 2. (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            "    (joint log prob.)\t:\t-15.18872\n",
            "\n",
            " 3. (continuation)\t:\tChronicles III was released in the United States on November 18 , 2012 . <eos>\n",
            "    (joint log prob.)\t:\t-15.19423\n",
            "\n",
            " 4. (continuation)\t:\tChronicles III was released in the United States on November 7 , 2010 . <eos>\n",
            "    (joint log prob.)\t:\t-15.24441\n",
            "\n",
            "(Beam Search BFS w/ beam size = 5 results):\n",
            " -  (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            "\n",
            " 1. (continuation)\t:\tChronicles III was released in the United States . <eos>\n",
            "    (joint log prob.)\t:\t-9.09503\n",
            "\n",
            " 2. (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            "    (joint log prob.)\t:\t-15.18872\n",
            "\n",
            " 3. (continuation)\t:\tChronicles III was released in the United States on November 18 , 2012 . <eos>\n",
            "    (joint log prob.)\t:\t-15.19423\n",
            "\n",
            " 4. (continuation)\t:\tChronicles III was released in the United States on November 7 , 2010 . <eos>\n",
            "    (joint log prob.)\t:\t-15.24441\n",
            "\n",
            " 5. (continuation)\t:\tChronicles III was released in the United States on November 18 , 2010 . <eos>\n",
            "    (joint log prob.)\t:\t-15.33842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = '''Outside missions , the player characters rest in a camp'''\n",
        "gt_cont = ''', where units can be customized and character growth occurs .'''\n",
        "\n",
        "print('''(Original Sentence):''')\n",
        "print(f' - (prefix)\\t\\t:\\t{prefix}')\n",
        "print(f' - (ground truth cont.)\\t:\\t{gt_cont}')\n",
        "\n",
        "greedy(prefix)\n",
        "beam_search_bfs(prefix, beam_size=1, n_best=1)\n",
        "beam_search_bfs(prefix, beam_size=2, n_best=2)\n",
        "beam_search_bfs(prefix, beam_size=3, n_best=3)\n",
        "beam_search_bfs(prefix, beam_size=4, n_best=4)\n",
        "beam_search_bfs(prefix, beam_size=5, n_best=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZEvZsETVnbW",
        "outputId": "782c747c-854c-47d7-a100-a5324d2c27d0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (ground truth cont.)\t:\t, where units can be customized and character growth occurs .\n",
            "\n",
            "(Greedy Decoding Result):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (continuation)\t:\t, and the player is able to make a new role in the game . <eos>\n",
            " - (log prob. of seq.)\t:\t-30.65266\n",
            "\n",
            "(Beam Search BFS w/ beam size = 1 results):\n",
            " -  (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            "\n",
            " 1. (continuation)\t:\t, and the player is able to make a new role in the game . <eos>\n",
            "    (joint log prob.)\t:\t-30.65266\n",
            "\n",
            "(Beam Search BFS w/ beam size = 2 results):\n",
            " -  (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            "\n",
            " 1. (continuation)\t:\t. <eos>\n",
            "    (joint log prob.)\t:\t-2.65808\n",
            "\n",
            " 2. (continuation)\t:\t, and the player can be seen as a <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-21.75920\n",
            "\n",
            "(Beam Search BFS w/ beam size = 3 results):\n",
            " -  (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            "\n",
            " 1. (continuation)\t:\t. <eos>\n",
            "    (joint log prob.)\t:\t-2.65808\n",
            "\n",
            " 2. (continuation)\t:\t, and the player can be seen as a <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-21.75920\n",
            "\n",
            " 3. (continuation)\t:\t, and the player can be seen as a player . <eos>\n",
            "    (joint log prob.)\t:\t-22.30766\n",
            "\n",
            "(Beam Search BFS w/ beam size = 4 results):\n",
            " -  (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            "\n",
            " 1. (continuation)\t:\t. <eos>\n",
            "    (joint log prob.)\t:\t-2.65808\n",
            "\n",
            " 2. (continuation)\t:\twith a <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-9.09437\n",
            "\n",
            " 3. (continuation)\t:\twith a <unk> and a <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-14.67251\n",
            "\n",
            " 4. (continuation)\t:\twith a <unk> , a <unk> , and a <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-20.66153\n",
            "\n",
            "(Beam Search BFS w/ beam size = 5 results):\n",
            " -  (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            "\n",
            " 1. (continuation)\t:\t. <eos>\n",
            "    (joint log prob.)\t:\t-2.65808\n",
            "\n",
            " 2. (continuation)\t:\twith a <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-9.09437\n",
            "\n",
            " 3. (continuation)\t:\twith a <unk> and a <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-14.67251\n",
            "\n",
            " 4. (continuation)\t:\twith a <unk> , a <unk> , and a <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-20.66153\n",
            "\n",
            " 5. (continuation)\t:\twith a <unk> , a <unk> , and a <unk> <unk> . <eos>\n",
            "    (joint log prob.)\t:\t-22.88389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `fairseq` Beam Search Result:"
      ],
      "metadata": {
        "id": "ozzYodSXGLWb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "A_ZzVrzfHcsH",
        "outputId": "ef37bf3e-b041-4155-fb90-06fa52cbc75e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Je ▁m & ap os ; ▁appelle ▁E ug ène ▁. ▁C & ap os ; ▁est ▁un ▁plais ir ▁de ▁vous ▁rencont rer ▁tous ▁.\n",
            "W-0\t0.184\tseconds\n",
            "H-0\t-11.106468200683594\t▁I ' m ▁called ▁E ug ene . ▁It ' s ▁a ▁pleasure ▁to ▁meet ▁you ▁all .\n",
            "D-0\t-11.106468200683594\tI'm called Eugene. It's a pleasure to meet you all.\n",
            "P-0\t-0.4590 -0.4913 -0.0948 -1.6790 -0.0227 -0.0410 -0.8890 -0.6845 -3.0094 -0.1736 -0.1152 -0.3796 -0.9266 -0.1985 -0.1228 -1.3209 -0.1568 -0.2279 -0.1139\n",
            "H-0\t-11.174216270446777\t▁I ' m ▁called ▁E ug ene . ▁It ' s ▁a ▁pleasure ▁to ▁meet ▁all ▁of ▁you .\n",
            "D-0\t-11.174216270446777\tI'm called Eugene. It's a pleasure to meet all of you.\n",
            "P-0\t-0.4590 -0.4913 -0.0948 -1.6790 -0.0227 -0.0410 -0.8890 -0.6845 -3.0094 -0.1736 -0.1152 -0.3796 -0.9266 -0.1985 -0.1228 -1.3500 -0.1019 -0.1198 -0.2019 -0.1137\n",
            "H-0\t-11.695176124572754\t▁I ' m ▁called ▁E ug ene . ▁That ' s ▁a ▁pleasure ▁to ▁meet ▁you ▁all .\n",
            "D-0\t-11.695176124572754\tI'm called Eugene. That's a pleasure to meet you all.\n",
            "P-0\t-0.4590 -0.4913 -0.0948 -1.6790 -0.0227 -0.0410 -0.8890 -0.6845 -2.2958 -0.9059 -0.1132 -0.5170 -1.2826 -0.2597 -0.1267 -1.3354 -0.1655 -0.2187 -0.1134\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Je m'appelle Eugène. C'est un plaisir de vous rencontrer tous.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --beam 5 --nbest 3 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"salut mon nom est max, je suis assistant d'enseignement pour le cours de maîtrise africaine en PNL\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --beam 5 --nbest 3 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTRWReCPVY1C",
        "outputId": "4b414a32-ae77-489b-a3e2-564acb22725b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁sal ut ▁mon ▁nom ▁est ▁ma x ▁, ▁je ▁suis ▁ass istant ▁d & ap os ; ▁enseign ement ▁pour ▁le ▁cours ▁de ▁ma î tr ise ▁af ric aine ▁en ▁P N L\n",
            "W-0\t0.275\tseconds\n",
            "H-0\t-21.150461196899414\t▁And ▁my ▁name ▁is ▁a ▁ma x , ▁and ▁I ' m ▁an ▁ass istant ▁teacher ▁for ▁the ▁African ▁master y ▁course ▁in ▁P N L .\n",
            "D-0\t-21.150461196899414\tAnd my name is a max, and I'm an assistant teacher for the African mastery course in PNL.\n",
            "P-0\t-2.1503 -0.6402 -0.0393 -0.4528 -1.8780 -1.0858 -0.0335 -0.8115 -0.4287 -0.2614 -0.4921 -0.0519 -2.6163 -1.2925 -0.1155 -2.9293 -0.7830 -0.9745 -1.1706 -0.3615 -1.0977 -0.2213 -0.3683 -0.0737 -0.0578 -0.5497 -0.1004 -0.1127\n",
            "H-0\t-23.984819412231445\t▁And ▁my ▁name ▁is ▁a ▁ma x , ▁and ▁I ' m ▁an ▁African ▁master ' s ▁ass istant ▁teacher ▁for ▁P N L ▁course .\n",
            "D-0\t-23.984819412231445\tAnd my name is a max, and I'm an African master's assistant teacher for PNL course.\n",
            "P-0\t-2.1503 -0.6402 -0.0393 -0.4528 -1.8780 -1.0858 -0.0335 -0.8115 -0.4287 -0.2614 -0.4921 -0.0519 -2.6163 -2.0179 -0.6132 -0.8938 -0.1015 -1.0441 -0.2531 -1.7257 -0.6842 -3.3314 -0.0814 -0.7269 -1.3038 -0.1554 -0.1105\n",
            "H-0\t-24.58407211303711\t▁And ▁my ▁name ▁is ▁a ▁ma x , ▁and ▁I ' m ▁an ▁ass istant ▁teacher ▁for ▁the ▁African ▁master ' s ▁course ▁in ▁P N L .\n",
            "D-0\t-24.58407211303711\tAnd my name is a max, and I'm an assistant teacher for the African master's course in PNL.\n",
            "P-0\t-2.1503 -0.6402 -0.0393 -0.4528 -1.8780 -1.0858 -0.0335 -0.8115 -0.4287 -0.2614 -0.4921 -0.0519 -2.6163 -1.2925 -0.1155 -2.9293 -0.7830 -0.9745 -1.1706 -0.3615 -1.9672 -0.1013 -2.0161 -1.0886 -0.0478 -0.0611 -0.5112 -0.1087 -0.1132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Bonjour, je m'appelle Stephen Kiilu. Je suis étudiant à AIMS Sénégal.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --beam 5 --nbest 3 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSfW8V9JaeuA",
        "outputId": "992f72f8-e591-41a0-8f46-f8e2d1527360"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Bon jour ▁, ▁je ▁m & ap os ; ▁appelle ▁Step hen ▁K i il u ▁. ▁Je ▁suis ▁étud iant ▁à ▁A I MS ▁S én ég al ▁.\n",
            "W-0\t0.284\tseconds\n",
            "H-0\t-10.756364822387695\t▁H ell o , ▁I ' m ▁m ap os ; ▁Step hen ▁K i il u . ▁I ' m ▁a ▁student ▁at ▁A I MS ▁S ene gal .\n",
            "D-0\t-10.756364822387695\tHello, I'm mapos; Stephen Kiilu. I'm a student at AIMS Senegal.\n",
            "P-0\t-0.3531 -0.5659 -0.0138 -0.3345 -0.2247 -0.8498 -0.0724 -2.1625 -1.2037 -0.1183 -0.2667 -0.4159 -0.0093 -0.0212 -0.1306 -0.0474 -0.0097 -2.0752 -0.2214 -0.1957 -0.0483 -0.1106 -0.1980 -0.2363 -0.0917 -0.0668 -0.0537 -0.1731 -0.1155 -0.1313 -0.1252 -0.1140\n",
            "H-0\t-11.557013511657715\t▁H ell o , ▁I ' m ▁m ap os ; ▁Step hen ▁K i il u ▁-- ▁I ' m ▁a ▁student ▁at ▁A I MS ▁S ene gal .\n",
            "D-0\t-11.557013511657715\tHello, I'm mapos; Stephen Kiilu -- I'm a student at AIMS Senegal.\n",
            "P-0\t-0.3531 -0.5659 -0.0138 -0.3345 -0.2247 -0.8498 -0.0724 -2.1625 -1.2037 -0.1183 -0.2667 -0.4159 -0.0093 -0.0212 -0.1306 -0.0474 -0.0097 -2.8106 -0.2240 -0.1921 -0.0472 -0.1128 -0.2308 -0.2250 -0.0921 -0.0726 -0.0533 -0.2067 -0.1103 -0.1395 -0.1253 -0.1150\n",
            "H-0\t-11.707371711730957\t▁H ell o , ▁I ' m ▁m ap os ; ▁Step hen ▁K i il u ; ▁I ' m ▁a ▁student ▁at ▁A I MS ▁S ene gal .\n",
            "D-0\t-11.707371711730957\tHello, I'm mapos; Stephen Kiilu; I'm a student at AIMS Senegal.\n",
            "P-0\t-0.3531 -0.5659 -0.0138 -0.3345 -0.2247 -0.8498 -0.0724 -2.1625 -1.2037 -0.1183 -0.2667 -0.4159 -0.0093 -0.0212 -0.1306 -0.0474 -0.0097 -3.0698 -0.1233 -0.2000 -0.0529 -0.1156 -0.1636 -0.2292 -0.0989 -0.0697 -0.0512 -0.2528 -0.1015 -0.1429 -0.1226 -0.1136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"qu'est-ce que j'aime le plus ? Étudier et voyager.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --beam 5 --nbest 3 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU9Xn_9Ba-AY",
        "outputId": "b6a04487-769b-4946-d95f-eeccc74e441f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁qu & ap os ; ▁est ▁ @ - @ ▁ce ▁que ▁j & ap os ; ▁a ime ▁le ▁plus ▁? ▁Ét ud ier ▁et ▁voy ager ▁.\n",
            "W-0\t0.224\tseconds\n",
            "H-0\t-12.754413604736328\t▁What ' s ▁the ▁most ▁lo ving ▁thing ? ▁Stud ying ▁and ▁traveling .\n",
            "D-0\t-12.754413604736328\tWhat's the most loving thing? Studying and traveling.\n",
            "P-0\t-0.3737 -2.7513 -0.1048 -1.8267 -0.5855 -1.4379 -0.1355 -0.7544 -0.8722 -1.4156 -1.8631 -0.1366 -0.0827 -0.3104 -0.1040\n",
            "H-0\t-15.792755126953125\t▁What ' s ▁the ▁most ▁lo ving ▁thing ? ▁Stud ent ▁and ▁travel .\n",
            "D-0\t-15.792755126953125\tWhat's the most loving thing? Student and travel.\n",
            "P-0\t-0.3737 -2.7513 -0.1048 -1.8267 -0.5855 -1.4379 -0.1355 -0.7544 -0.8722 -1.4156 -1.3994 -2.0029 -1.3574 -0.6696 -0.1058\n",
            "H-0\t-23.945585250854492\t▁What ▁is ▁it ▁about ▁ @ - @ - @ - @ ▁what ▁I ap os ▁most ▁love ? ▁Stud ying ▁and ▁traveling .\n",
            "D-0\t-23.945585250854492\tWhat is it about @-@-@-@ what Iapos most love? Studying and traveling.\n",
            "P-0\t-0.3737 -1.1579 -3.4848 -0.8445 -1.7559 -0.1248 -0.0978 -0.2148 -0.4196 -0.3050 -1.6628 -0.3954 -1.7758 -2.0340 -3.0096 -0.0800 -0.1845 -1.7253 -0.2658 -1.4616 -2.0384 -0.1380 -0.0640 -0.2258 -0.1057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeVHX-ORQBOb"
      },
      "source": [
        "### Variants of the greedy search:\n",
        "* Trainable Greedy Decoding for Neural Machine Translation (Gu, Cho, Li 2017) [(paper)](https://arxiv.org/abs/1702.02429)\n",
        "* Amortized Noisy Channel Neural Machine Translation (Pang, He, Cho 2021) [(paper)](https://arxiv.org/abs/2112.08670#:~:text=Noisy%20channel%20models%20have%20been,making%20real%2Dworld%20application%20infeasible.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS1A4TSp5Fcg"
      },
      "source": [
        "### Variants of the beam search:\n",
        "* Noisy parallel approximate decoding (NPAD) (Cho 2016) [(paper)](https://arxiv.org/abs/1605.03835)\n",
        "  * Parallized beam search using a stochastic transition function exploiting the local structure of the manifold learned by neural networks.\n",
        "  * Induces more diversity and an improved `BLEU` scrore.\n",
        "* FCFS Beam Decoding with Controlled Patience (Kasai et. al. 2022) [(paper)](https://arxiv.org/abs/2204.05424)\n",
        "  * Encourages a wider breadth than the vanila beam search (decodes $k$ unfinished sequences at every step regardless of how many sequences are finished with the $\\langle eos \\rangle$ token).\n",
        "  * Improved performance in:\n",
        "    * News text summarization\n",
        "    * Machine translation over diverse language pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i7LVrJPxe3s",
        "tags": []
      },
      "source": [
        "## 1.2) Stochastic Decoding Algorithms:\n",
        "\n",
        "### Why sampling?\n",
        "\n",
        "* Why should we use sampling?\n",
        "\n",
        "* In which settings would stochastic decoding algorithms be more appropriate than the deterministic decoding algorithms and why?\n",
        "  * Within low entropy distributions, sampling with replacement will produce many duplicates, and leveraging deterministic beam search will result in low variability.\n",
        "\n",
        "  * Beam search is great at finding high probability sequences, but both greedy search and beam search often run into problems with repetition, decoding the same high-probability sequence over and over again.\n",
        "\n",
        "\n",
        "### Text generation with sampling:\n",
        "\n",
        "* Sampling, in the text generation context, refers to randomly selecting the next token based on the probability distribution over the entire vocabulary given by the model. This means that every token with a non-zero probability has a chance of being selected. \n",
        "    * For example, the probability distribution of the next token for `the boy went to the` might be:\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*2i-ivI_5aGAbO0ONcnL87g.png\" width=400 height=300>\n",
        "\n",
        "* In this hypothetical example, we see that while the most likely subsequent word is $“park”$, with $P(“park”| S) =0.36$, it’s still more probable that the selected word will be something else, $1-P(“park”| S) = 0.64$. This adds diversity to our samples, at the cost of reducing the total probability of our sequence when a low-probability word is chosen.\n",
        "\n",
        "* What if we want to make our sampler more likely to choose the high probability words, and less likely to choose the low probability words? We can make the $PMF$ sharper by lowering the `temperature` parameter, which reduces the entropy of the resulting Softmax output:\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*JEnPzPtGVRoIP_f_7CJ7og.png\" width=400 height=300>\n",
        "\n",
        "* Let’s go back to the original non-sharpened $PMF$ above. Even though this distribution has two high probability words, the cumulative probability of the thousands of other possible words sums up to $~0.35$. Even though each of these words is low probability (and most wouldn’t make for a great sequence) the effect of the long tail means that there is still a significant chance that a rather low probability word could be chosen, which results in some strange outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvxg0mYYCjsB"
      },
      "source": [
        "### 1.2.1) Ancestral (or Forward) Sampling:\n",
        "$$\n",
        "\\hat{y}_t \\sim p_\\theta (y_t \\mid y_{<t}, X)\n",
        "$$\n",
        "\n",
        "\n",
        "* Simply sample tokens in topological order (in time going forward). \n",
        "  * Start by sampling the variables with no parents; then we sample from the next generation by conditioning these variables’ conditional probability distributions to values sampled at the first step.\n",
        "  * We proceed like this until we sample $\\langle eos \\rangle$.\n",
        "  * Linear $\\mathcal{O}(|\\mathcal{V}|\\cdot T)$ time to sample a sequence.\n",
        "\n",
        "<img src=\"https://deepgenerativemodels.github.io/notes/autoregressive/\n",
        "autoregressive.png\" width=350>\n",
        "\n",
        "* Unbiased estimator of $p_\\theta$.\n",
        "\n",
        "* Minimum Bayes Risk Decoding:\n",
        "  * \"Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural Machine Translation\" (Eikema, Aziz 2020) [(paper)](https://arxiv.org/abs/2005.10283)\n",
        "  * \"Sampling-Based Minimum Bayes Risk Decoding for Neural Machine Translation\" (Eikema, Aziz 2020) [(paper)](https://arxiv.org/abs/2108.04718) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_decode(model:nn.Module, prefix:str, vocab:object, temperature:float=1.0) -> (torch.Tensor, torch.Tensor):\n",
        "    \"\"\"\n",
        "    Implements the ancestral sampling algorithm for decoding a sequence given the prefix.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        Our model (2-layer LSTM trained on wikitext-2) which will generate the continuation of the given prefix.\n",
        "    prefix: str\n",
        "        A string of tokens given as a context. \n",
        "    vocab: object\n",
        "        A dictionary object for encoding tokens into corresponding indicies and vice-versa.\n",
        "    temperature:float\n",
        "        The temperature parameter that controls the shape (peakiness) of the output distribution.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    (torch.Tensor, torch.Tensor): tuple\n",
        "        List of ``(predictions, log_probs)``, where ``predictions``\n",
        "        has shape ``(MAX_LENGTH)`` and ``log_probs``\n",
        "        has shape ``(MAX_LENGTH)``.        \n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    # set the max. generation length as MAX_LENGTH. use <pad> tokens as placeholders for the tensor to store the decoded tokens.\n",
        "    predictions = (torch.ones(MAX_LENGTH)*PAD_IDX).int()\n",
        "    log_probs = torch.zeros(MAX_LENGTH)\n",
        "    \n",
        "    # encode the prefix given as a string into integer indices corresponding to their indices in the vocab set.\n",
        "    decoder_input =  torch.tensor([[BOS_IDX]+vocab.encode_token_seq(prefix.split())],device=device)\n",
        "    decoder_hidden = None\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for t in range(MAX_LENGTH):\n",
        "            decoder_logits, decoder_hidden = model.step(decoder_input, decoder_hidden)\n",
        "            output_dist = decoder_logits[0,-1,:].softmax(-1) # selecting the last timestep (for encoding the prefix.)\n",
        "            vocab_idx = (output_dist / temperature).multinomial(1)  # get candidates; softmax added to compute joint lporb\n",
        "            \n",
        "            top_log_prob, top_vocab_idx = decoder_logits.log_softmax(-1).topk(1)  # get candidates; softmax added to compute joint lporb\n",
        "            \n",
        "            predictions[t] = vocab_idx.item()\n",
        "            log_probs[t] = output_dist[vocab_idx].log().item()\n",
        "            \n",
        "            if vocab_idx.item() == EOS_IDX:\n",
        "                break    \n",
        "                \n",
        "            decoder_input = vocab_idx.unsqueeze(0)\n",
        "            \n",
        "    return (predictions, log_probs)"
      ],
      "metadata": {
        "id": "gFWXb3ApYKY4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ancestral_sampling(prefix:str, temperature:float=1.0):\n",
        "    predictions, log_probs = sample_decode(model, prefix, vocab, temperature)\n",
        "    predictions = [token for token in vocab.decode_idx_seq(predictions.tolist()) if token != '<pad>']\n",
        "    predictions = \" \".join(token for token in predictions).strip()\n",
        "    log_probs = log_probs[log_probs.nonzero(as_tuple=True)[0]]\n",
        "    \n",
        "    print(f'\\n(Ancestral sampling w/ temp = {temperature} result):')\n",
        "    print(f' - (prefix)\\t\\t:\\t{prefix}')\n",
        "    print(f' - (continuation)\\t:\\t{predictions}')\n",
        "    print(f' - (joint log prob.)\\t:\\t{log_probs.sum():.5f}')"
      ],
      "metadata": {
        "id": "Wk72zCb8YKXY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('''(Original Sentence):''')\n",
        "print('''Outside missions , the player characters rest in a camp \\n, where units can be customized and character growth occurs .''')\n",
        "prefix = '''Outside missions , the player characters rest in a camp'''\n",
        "\n",
        "ancestral_sampling(prefix,temperature=1.0)\n",
        "ancestral_sampling(prefix,temperature=0.5)\n",
        "ancestral_sampling(prefix,temperature=0.1)\n",
        "ancestral_sampling(prefix,temperature=2.0)\n",
        "ancestral_sampling(prefix,temperature=5.0)"
      ],
      "metadata": {
        "id": "Yqt80PgDYUzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a582acea-ddca-4641-ea6c-894108dd88a0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            "Outside missions , the player characters rest in a camp \n",
            ", where units can be customized and character growth occurs .\n",
            "\n",
            "(Ancestral sampling w/ temp = 1.0 result):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (continuation)\t:\tthe ground is most of a second @-@ down prosecutor . <eos>\n",
            " - (joint log prob.)\t:\t-52.67161\n",
            "\n",
            "(Ancestral sampling w/ temp = 0.5 result):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (continuation)\t:\tto perform a foul , and heresy would see entirely from ways to the extent of convict in the depth serious he . <eos>\n",
            " - (joint log prob.)\t:\t-127.79742\n",
            "\n",
            "(Ancestral sampling w/ temp = 0.1 result):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (continuation)\t:\tregardless of Eliot . <eos>\n",
            " - (joint log prob.)\t:\t-24.95786\n",
            "\n",
            "(Ancestral sampling w/ temp = 2.0 result):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (continuation)\t:\twhen Mariana match the wing , a pair of podium trees . <eos>\n",
            " - (joint log prob.)\t:\t-63.11459\n",
            "\n",
            "(Ancestral sampling w/ temp = 5.0 result):\n",
            " - (prefix)\t\t:\tOutside missions , the player characters rest in a camp\n",
            " - (continuation)\t:\tto see an horror without Lowe . <eos>\n",
            " - (joint log prob.)\t:\t-40.98469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('''(Original Sentence):''')\n",
        "print('''Due to low sales of Valkyria Chronicles II , Valkyria \\nChronicles III was not localized , but a \\\n",
        "fan translation compatible with the game 's expanded edition was released in 2014 .''')\n",
        "prefix = '''Due to low sales of Valkyria Chronicles II , Valkyria'''\n",
        "\n",
        "ancestral_sampling(prefix,temperature=1.0)\n",
        "ancestral_sampling(prefix,temperature=0.5)\n",
        "ancestral_sampling(prefix,temperature=0.1)\n",
        "ancestral_sampling(prefix,temperature=2.0)\n",
        "ancestral_sampling(prefix,temperature=5.0)"
      ],
      "metadata": {
        "id": "07xXtnJyYUzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09295d3-ce62-4efd-f6a0-7819bf897258"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            "Due to low sales of Valkyria Chronicles II , Valkyria \n",
            "Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 .\n",
            "\n",
            "(Ancestral sampling w/ temp = 1.0 result):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (continuation)\t:\tChronicles III in Sarajevo drew a number of sales , and then were not released until March 29 , 2012 . <eos>\n",
            " - (joint log prob.)\t:\t-60.96267\n",
            "\n",
            "(Ancestral sampling w/ temp = 0.5 result):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (continuation)\t:\tChronicles was expanded by the controversy to gain commercial commentary to develop control lbw on an once @-@ previous film television film for its original film on make him play . <eos>\n",
            " - (joint log prob.)\t:\t-167.04460\n",
            "\n",
            "(Ancestral sampling w/ temp = 0.1 result):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (continuation)\t:\tChronicles II was that up to 12 % , it did not appear when women were used to be examining . <eos>\n",
            " - (joint log prob.)\t:\t-76.65320\n",
            "\n",
            "(Ancestral sampling w/ temp = 2.0 result):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (continuation)\t:\tChronicles III , the album was not it an amount of attention to the series still forming of cast metal artists . <eos>\n",
            " - (joint log prob.)\t:\t-96.81577\n",
            "\n",
            "(Ancestral sampling w/ temp = 5.0 result):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (continuation)\t:\tChronicles III was arrested ; however , the band was acclaimed as president of the Year @-@ Day . <eos>\n",
            " - (joint log prob.)\t:\t-61.24146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "L-DB26roHcsJ",
        "outputId": "f0ac444f-f190-4bf6-f43c-482ee79b408e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁J e ▁m & ap os ; ▁appelle ▁E ug è n e ▁. ▁C & ap os ; ▁est ▁un ▁plais ir ▁de ▁vous ▁rencont rer ▁tous ▁.\n",
            "W-0\t0.269\tseconds\n",
            "H-0\t-44.91563415527344\t▁J ap h os ; ▁E ug ian e . ▁C ap os ▁is ▁del ight ed ▁to ▁meet ▁all ▁of ▁you .\n",
            "D-0\t-44.91563415527344\tJaphos; Eugiane. Capos is delighted to meet all of you.\n",
            "P-0\t-0.1368 -5.0485 -1.5321 -2.5923 -0.9704 -2.1238 -0.0547 -9.3304 -6.9776 -2.6720 -0.5047 -0.0110 -0.0176 -2.5210 -5.5440 -0.0038 -2.8520 -0.2001 -0.1365 -1.1452 -0.1067 -0.1707 -0.1503 -0.1135\n",
            "H-0\t-50.527427673339844\t▁J es la ▁m ap os ; ▁E ug ene ▁-- ▁C ap os os ▁is ▁enjoy able ▁to ▁meet ▁all ▁of ▁you ▁Jew ish .\n",
            "D-0\t-50.527427673339844\tJesla mapos; Eugene -- Caposos is enjoyable to meet all of you Jewish.\n",
            "P-0\t-0.1368 -1.0198 -5.3977 -1.8754 -0.4541 -0.0490 -0.4837 -2.1335 -0.0406 -5.2272 -4.7490 -0.4002 -0.0147 -0.0114 -1.0247 -2.8967 -4.0339 -1.8826 -0.4449 -0.1729 -1.2748 -0.1474 -0.1707 -16.1684 -0.0529 -0.1495 -0.1150\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Je m'appelle Eugène. C'est un plaisir de vous rencontrer tous.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topp 1.0 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Bq_1ptRHHcsJ",
        "outputId": "bfc070d1-bf03-4fbf-f742-6b2888811459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁sal ut ▁mon ▁n om ▁est ▁ma x ▁, ▁je ▁suis ▁ass istant ▁d & ap os ; ▁ense ig nement ▁pour ▁le ▁c ours ▁de ▁ma î tr ise ▁af r ic aine ▁en ▁P N L\n",
            "W-0\t0.347\tseconds\n",
            "H-0\t-56.78592300415039\t▁W age ▁my ▁n om ▁is ▁c ute , ▁I ' m ▁an ▁educ ational ▁ass istant ▁to ▁the ▁coast ▁of ▁Africa ' ▁dra wer ▁in ▁P N N L .\n",
            "D-0\t-56.78592300415039\tWage my nom is cute, I'm an educational assistant to the coast of Africa' drawer in PNNL.\n",
            "P-0\t-3.0073 -3.2075 -0.6278 -0.0707 -1.5110 -0.2071 -7.7258 -1.5910 -0.3497 -0.5155 -0.4983 -0.0460 -1.6919 -4.3628 -0.7782 -0.5644 -0.2718 -1.5857 -0.3269 -3.4399 -0.1669 -3.0561 -0.1263 -16.5499 -2.2474 -0.2596 -0.1379 -0.0398 -1.2582 -0.3530 -0.0992 -0.1125\n",
            "H-0\t-79.19268035888672\t▁did ▁not ▁pay ▁for ▁my ▁n om ▁is ▁compr om ise , ▁I ' m ▁an ▁adv oc ate ▁for ▁running ▁African ▁master ' s ▁c age ▁in ▁P N N N T .\n",
            "D-0\t-79.19268035888672\tdid not pay for my nom is compromise, I'm an advocate for running African master's cage in PNNNT.\n",
            "P-0\t-13.6102 -3.0653 -1.3837 -4.3137 -0.4321 -0.5486 -1.1608 -0.5961 -12.0060 -0.1123 -1.0987 -0.5412 -0.4975 -0.8167 -0.0425 -2.2799 -5.4402 -0.0148 -0.2386 -0.1459 -9.1024 -0.9887 -0.2123 -0.9093 -0.1034 -3.3862 -1.5841 -0.9103 -0.1524 -0.0523 -1.0220 -5.4722 -6.7259 -0.1131 -0.1135\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"salut mon nom est max, je suis assistant d'enseignement pour le cours de maîtrise africaine en PNL\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topp 1.0 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout \n",
        "%%bash\n",
        "echo \"Bonjour, je m'appelle Stephen Kiilu. Je suis étudiant à AIMS Sénégal.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topp 1.0 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSaiAdX8fy8G",
        "outputId": "e8850fa2-60ed-463e-e389-dbbcfda28180"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Bon jour ▁, ▁je ▁m & ap os ; ▁appelle ▁S te p hen ▁K i il u ▁. ▁J e ▁su i s ▁étud iant ▁à ▁A I M S ▁S én ég al ▁.\n",
            "W-0\t0.385\tseconds\n",
            "H-0\t-32.45668411254883\t▁H ell o , ▁I ' m ▁m ap os ; ▁S te p hen ▁K i il u . ▁J es us ▁B at i ' s ▁student ▁at ▁A I M S S ene gal .\n",
            "D-0\t-32.45668411254883\tHello, I'm mapos; Stephen Kiilu. Jesus Bati's student at AIMSSenegal.\n",
            "P-0\t-0.4003 -0.4983 -0.0128 -0.3300 -0.3392 -0.7847 -0.0628 -1.8213 -1.5087 -0.0851 -0.3718 -0.7890 -0.4431 -0.0070 -0.0171 -0.0279 -0.0875 -0.0679 -0.0137 -1.9688 -0.3113 -0.1970 -0.4953 -6.2131 -2.2910 -3.0811 -2.6464 -0.0555 -0.8435 -0.0911 -0.0474 -0.0250 -0.0188 -0.2893 -1.7938 -3.8591 -0.2423 -0.2011 -0.1177\n",
            "H-0\t-81.97297668457031\t▁Thanks k . ▁Am ong st yle ! ▁First ▁time , ▁I ▁am ▁m asse .\n",
            "D-0\t-81.97297668457031\tThanksk. Amongstyle! First time, I am masse.\n",
            "P-0\t-7.8435 -10.6571 -5.1606 -9.3855 -1.6520 -0.2458 -6.4594 -6.1722 -13.6017 -2.5950 -0.6155 -0.1249 -2.4477 -4.5727 -8.0955 -1.9624 -0.3815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ApkWeVClnn",
        "tags": []
      },
      "source": [
        "### 1.2.2) Top-$k$ sampling\n",
        "\n",
        "* Proposed in \"Hierarchical Neural Story Generation\" paper (Fan et. al. 2018) [(paper)](https://arxiv.org/abs/1805.04833)\n",
        "\n",
        "* In Top-$K$ sampling, the idea is to only sample from the $k$ most probable tokens. For example, suppose we set $k=4$ (top figure), $k=6$ (bottom figure). This means we redistribute the $PMF$ over the four most probable tokens, and sample from those in the blue box/curly braces:\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*ixvVLan_Ll3MdLDEfJj5qA.png\" width=500 height =300> \n",
        "<img src=\"https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/top_k_sampling.png\" width=700 height =300>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_decode(model:nn.Module, prefix:str, vocab:object, k:int=5, \n",
        "                 filter_value:float=-float(\"Inf\"), min_tokens_to_keep:int=1,\n",
        "                 consistent_sampling:bool=False) -> (torch.Tensor, torch.Tensor):\n",
        "    \"\"\"\n",
        "    Implements the top-k sampling algorithm for decoding a sequence given the prefix.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        Our model (2-layer LSTM trained on wikitext-2) which will generate the continuation of the given prefix.\n",
        "    prefix: str\n",
        "        A string of tokens given as a context. \n",
        "    vocab: object\n",
        "        A dictionary object for encoding tokens into corresponding indicies and vice-versa.\n",
        "    k: int\n",
        "        The parameter that determines how many tokens with the highest proability to consider at each timestep.\n",
        "    filter_value: float\n",
        "        =-float(\"Inf\"), \n",
        "    min_tokens_to_keep: int\n",
        "        Minimum number of tokens to keep at each timestep.\n",
        "    consistent_sampling:=False\n",
        "        \n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    (torch.Tensor, torch.Tensor): tuple\n",
        "        List of ``(predictions, log_probs)``, where ``predictions``\n",
        "        has shape ``(MAX_LENGTH)`` and ``log_probs``\n",
        "        has shape ``(MAX_LENGTH)``.        \n",
        "    \"\"\"\n",
        "    \n",
        "    assert k > 0, \"k needs to be larger than 0.\"\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # set the max. generation length as MAX_LENGTH. use <pad> tokens as placeholders for the tensor to store the decoded tokens.\n",
        "    predictions = (torch.ones(MAX_LENGTH)*PAD_IDX).int()\n",
        "    log_probs = torch.zeros(MAX_LENGTH)\n",
        "    \n",
        "    # encode the prefix given as a string into integer indices corresponding to their indices in the vocab set.\n",
        "    decoder_input =  torch.tensor([[BOS_IDX]+vocab.encode_token_seq(prefix.split())],device=device)\n",
        "    decoder_hidden = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in range(MAX_LENGTH):\n",
        "            decoder_logits, decoder_hidden = model.step(decoder_input, decoder_hidden)\n",
        "            decoder_logits = decoder_logits[0,-1,:] # selecting the last timestep (for encoding the prefix.) / get candidates; softmax added to compute joint lporb\n",
        "            output_dist = decoder_logits.softmax(-1)\n",
        "            \n",
        "            if k > 0:\n",
        "                k = min(max(k, min_tokens_to_keep), decoder_logits.size(-1))  # Safety check\n",
        "                \n",
        "                # Remove all tokens with a probability less than the last token of the top-k\n",
        "                indices_to_remove = decoder_logits < torch.topk(decoder_logits, k)[0][..., -1, None]\n",
        "                if consistent_sampling:\n",
        "                    indices_to_remove[:, EOS_IDX].fill_(False)\n",
        "                decoder_logits[indices_to_remove] = filter_value\n",
        "                \n",
        "            filtered_output_dist = decoder_logits.softmax(-1)\n",
        "            vocab_idx = filtered_output_dist.multinomial(1).item()\n",
        "            predictions[t] = vocab_idx\n",
        "            log_probs[t] = output_dist[vocab_idx].log()\n",
        "            \n",
        "            if vocab_idx == EOS_IDX:\n",
        "                break    \n",
        "            decoder_input = torch.tensor([[vocab_idx]],device=device)\n",
        "            \n",
        "    return (predictions, log_probs)"
      ],
      "metadata": {
        "id": "aDC35RAmY70D"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_sampling(prefix:str, k:int=5, filter_value=-float(\"Inf\"), min_tokens_to_keep=1):\n",
        "    \n",
        "    decoded_seq, log_probs =  top_k_decode(model, prefix, vocab, k, filter_value=-float(\"Inf\"), min_tokens_to_keep=1)\n",
        "    decoded_seq = [token for token in vocab.decode_idx_seq(decoded_seq.tolist()) if token != '<pad>']\n",
        "    continuation = \" \".join(token for token in decoded_seq).strip()\n",
        "    log_probs = log_probs[log_probs.nonzero(as_tuple=True)[0]]\n",
        "    \n",
        "    print(f'\\n(Top-k sampling w/ k = {k} result):')\n",
        "    print(f' - (prefix)\\t:\\t{prefix}')\n",
        "    print(f' - (contin)\\t:\\t{continuation}')\n",
        "    print(f' - (joint-lprob):\\t{log_probs.sum():.5f}')"
      ],
      "metadata": {
        "id": "HUqPcOZCY7yE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('''(Original Sentence):''')\n",
        "print('''Due to low sales of Valkyria Chronicles II , Valkyria \\nChronicles III was not localized , but a \\\n",
        "fan translation compatible with the game 's expanded edition was released in 2014 .''')\n",
        "prefix = '''Due to low sales of Valkyria Chronicles II , Valkyria'''\n",
        "\n",
        "greedy(prefix)\n",
        "top_k_sampling(prefix,k=1) # same as greedy decoding.\n",
        "\n",
        "top_k_sampling(prefix,k=3)\n",
        "top_k_sampling(prefix,k=5)\n",
        "top_k_sampling(prefix,k=10)"
      ],
      "metadata": {
        "id": "7vkEiVXRoijJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5205d4f8-4697-4719-c0f4-11a814a1f84e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            "Due to low sales of Valkyria Chronicles II , Valkyria \n",
            "Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 .\n",
            "\n",
            "(Greedy Decoding Result):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            " - (log prob. of seq.)\t:\t-15.18872\n",
            "\n",
            "(Top-k sampling w/ k = 1 result):\n",
            " - (prefix)\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (contin)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            " - (joint-lprob):\t-15.18872\n",
            "\n",
            "(Top-k sampling w/ k = 3 result):\n",
            " - (prefix)\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (contin)\t:\tChronicles III was released on March 7 , 2008 , in a single @-@ game version , and a single DVD . <eos>\n",
            " - (joint-lprob):\t-46.41978\n",
            "\n",
            "(Top-k sampling w/ k = 5 result):\n",
            " - (prefix)\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (contin)\t:\tChronicles II was released in the United States and was released on December 26 , 2008 , and peaked at number nine on the Hot R & B / Hip @-@ Hop Songs . <eos>\n",
            " - (joint-lprob):\t-38.02481\n",
            "\n",
            "(Top-k sampling w/ k = 10 result):\n",
            " - (prefix)\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (contin)\t:\tChronicles III was released in October 2008 , but the release of the film was released in October 2012 . <eos>\n",
            " - (joint-lprob):\t-34.60171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ernN_aKKL66d",
        "outputId": "1af605be-f87f-4f5a-e390-c22cbbe27619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Je ▁m & ap os ; ▁appelle ▁E ug ène ▁. ▁C & ap os ; ▁est ▁un ▁plais i r ▁de ▁vous ▁rencont rer ▁tous ▁.\n",
            "W-0\t0.178\tseconds\n",
            "H-0\t-16.5825252532959\t▁I ' m ▁called ▁E ug gen . ▁That ' s ▁a ▁pleasure ▁to ▁meet ▁you ▁all .\n",
            "D-0\t-16.5825252532959\tI'm called Euggen. That's a pleasure to meet you all.\n",
            "P-0\t-0.4324 -0.4794 -0.0943 -1.7189 -0.0230 -0.0417 -2.1449 -1.4033 -2.5334 -1.3948 -0.1146 -0.5600 -3.2800 -0.3235 -0.1413 -1.4499 -0.1452 -0.1891 -0.1128\n",
            "H-0\t-21.65312385559082\t▁My ▁name ▁is ▁E ug ene . ▁That ▁ap ology ▁is ▁a ▁joy ▁to ▁meet ▁all ▁of ▁you .\n",
            "D-0\t-21.65312385559082\tMy name is Eugene. That apology is a joy to meet all of you.\n",
            "P-0\t-3.7632 -0.6591 -0.1495 -0.0148 -0.0431 -0.7284 -0.7728 -2.8709 -5.2952 -2.1033 -0.1783 -0.4937 -2.4207 -0.4188 -0.1189 -1.1418 -0.0899 -0.1291 -0.1516 -0.1102\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Je m'appelle Eugène. C'est un plaisir de vous rencontrer tous.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topk 10 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "kB7d_esbHcsK",
        "outputId": "e3d5236d-7ca9-43c2-ebe5-ca87fa371fde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁s al u t ▁m on ▁nom ▁est ▁ma x ▁ , ▁je ▁suis ▁a s s istant ▁d & a p os ; ▁ense ign ement ▁p our ▁le ▁cours ▁de ▁ma î t ri se ▁af ric aine ▁en ▁P N L\n",
            "W-0\t0.355\tseconds\n",
            "H-0\t-44.149452209472656\t▁And ▁my ▁name ▁is ▁my ▁m ic ron , ▁and ▁I ' m ▁a p os itive ▁a p os itive ▁sp ok esp ass er .\n",
            "D-0\t-44.149452209472656\tAnd my name is my micron, and I'm apositive apositive spokespasser.\n",
            "P-0\t-3.0351 -2.3743 -0.2251 -0.3890 -1.6328 -2.0889 -2.3012 -1.1007 -1.7896 -0.8831 -0.2246 -0.7983 -0.0860 -0.4212 -3.5366 -0.1478 -0.9089 -0.7938 -1.2269 -0.2177 -1.8635 -5.4514 -4.8994 -2.6950 -0.3257 -1.2645 -3.3537 -0.1150\n",
            "H-0\t-78.55989074707031\t▁M u pp u j ah ▁is ▁my ▁sl ime ▁m old , ▁I ▁am ▁a de qu ate ▁a p os itive ▁a p os itive ▁teaching ▁a ▁teacher ▁in ▁Africa ' s ▁master y ▁in ▁P N N .\n",
            "D-0\t-78.55989074707031\tMuppujah is my slime mold, I am adequate apositive apositive teaching a teacher in Africa's mastery in PNN.\n",
            "P-0\t-5.6167 -4.1940 -2.9744 -3.6141 -2.7115 -2.7280 -1.0363 -0.6607 -5.8104 -0.9464 -0.0239 -0.4858 -0.4496 -0.8701 -2.1598 -0.3979 -4.4858 -1.1889 -0.1609 -3.6581 -0.2256 -0.1929 -2.2938 -2.6216 -1.8695 -0.3342 -2.2688 -1.0295 -2.2089 -4.5322 -1.2030 -3.2016 -2.5178 -0.0900 -2.1785 -1.6274 -0.4186 -0.0939 -0.0289 -1.2289 -4.1099 -0.1110\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"salut mon nom est max, je suis assistant d'enseignement pour le cours de maîtrise africaine en PNL\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topk 10 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Bonjour, je m'appelle Stephen Kiilu. Je suis étudiant à AIMS Sénégal.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topk 10 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS3uLzuxhpVF",
        "outputId": "5f586aa5-8202-4e5e-9d12-3c472506c405"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Bon jour ▁, ▁je ▁m & ap os ; ▁a pp elle ▁S te p hen ▁K i il u ▁ . ▁Je ▁suis ▁ét ud iant ▁ à ▁A I MS ▁S én ég al ▁.\n",
            "W-0\t0.280\tseconds\n",
            "H-0\t-18.942569732666016\t▁H ell o , ▁I ' m ▁standing ▁up ▁with ▁S te p hen ▁K i il u ▁ + ▁I ' m ▁an ▁A I MS ▁student .\n",
            "D-0\t-18.942569732666016\tHello, I'm standing up with Stephen Kiilu + I'm an AIMS student.\n",
            "P-0\t-0.4033 -0.5171 -0.0139 -0.3526 -0.2661 -0.5281 -0.0669 -2.3491 -2.1052 -1.8864 -0.6354 -0.3199 -0.0013 -0.0329 -0.0391 -0.1169 -0.0205 -0.1049 -0.2853 -1.7866 -0.1590 -0.2754 -0.0430 -5.0704 -0.6301 -0.0629 -0.0573 -0.5713 -0.1235 -0.1180\n",
            "H-0\t-26.796419143676758\t▁Good ▁morning , ▁I ' m ▁a ▁m i xt ure ▁by ▁S te p hen ▁K i il u ▁ + ▁I ' m ▁a ▁student ▁at ▁A I MS .\n",
            "D-0\t-26.796419143676758\tGood morning, I'm a mixture by Stephen Kiilu + I'm a student at AIMS.\n",
            "P-0\t-3.2788 -0.1815 -0.4573 -0.2001 -0.9609 -0.1048 -3.0595 -4.7507 -3.8247 -0.3746 -0.0708 -4.2940 -0.2428 -0.3722 -0.0012 -0.0219 -0.0352 -0.0994 -0.0157 -0.1453 -0.4586 -1.7649 -0.2380 -0.3354 -0.0423 -0.1348 -0.4730 -0.3513 -0.0680 -0.0402 -0.0857 -0.1958 -0.1170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVY-0Aq9HcsK"
      },
      "source": [
        "* This has the advantage of removing many the lowest probability words. \n",
        "\n",
        "\n",
        "* However, picking a good value of $k$ can be difficult as the distribution or words is different for each step. This means that the same value of $k$ can allow for strange words to be included in one step, while also excluding reasonable words in a different step. In order to get around this, we can leverage a different sampling technique: Top-$p$ sampling.\n",
        "\n",
        "<img src=\"https://lena-voita.github.io/resources/lectures/lang_models/sampling/topk_problems-min.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcJIS4tICqO_"
      },
      "source": [
        "### 1.2.3) Nucleus (top-$p$) sampling\n",
        "\n",
        "* Proposed in \"The Curious Case of Neural Text Degeneration\" paper (Holtzman et. al. 2020) [(paper)](https://arxiv.org/abs/1904.09751)\n",
        "\n",
        "* Very similar to top-$k$ sampling, in the sense a way to exclude very low probability tokens is to include the most probable tokens that make up the “nucleus” of the $PMF$, such that the sum of the most probable tokens just reaches $p$. \n",
        "\n",
        "* For example, suppose we set $p = 0.75$; with Top-$P$ sampling, we would include the most probable next tokens until the cumulative probability until the sum reaches $0.75$, at which point we stop including tokens.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*9HEQLJLkPe1Tc1VwIYk5Iw.png\" width=500 height =300> \n",
        "\n",
        "<img src=\"https://github.com/patrickvonplaten/scientific_images/blob/master/top_p_sampling.png?raw=true\" width=700 height =300> \n",
        "\n",
        "\n",
        "* This has the advantage of being flexible as the distribution changes, allowing the size of the filtered words to expand and contract when it makes sense.\n",
        "\n",
        "\n",
        "* With nucleus sampling, the number of tokens we sample from is dynamic and depends on the properties of the distribution."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def top_p_decode(model:nn.Module, prefix:str, vocab:object, p:float=0.5, \n",
        "                 filter_value:float=-float(\"Inf\"), min_tokens_to_keep:int=1,\n",
        "                 consistent_sampling=False,) -> (torch.Tensor, torch.Tensor):\n",
        "    \"\"\"\n",
        "    Implements the nucleus (top-p) sampling algorithm for decoding a sequence given the prefix.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        Our model (2-layer LSTM trained on wikitext-2) which will generate the continuation of the given prefix.\n",
        "    prefix: str\n",
        "        A string of tokens given as a context. \n",
        "    vocab: object\n",
        "        A dictionary object for encoding tokens into corresponding indicies and vice-versa.\n",
        "    p: float\n",
        "        The parameter that determines how many tokens with the highest proability to consider at each timestep.\n",
        "    filter_value: float\n",
        "        =-float(\"Inf\"), \n",
        "    min_tokens_to_keep: int\n",
        "        Minimum number of tokens to keep at each timestep.\n",
        "    consistent_sampling:=False\n",
        "        \n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    (torch.Tensor, torch.Tensor): tuple\n",
        "        List of ``(predictions, log_probs)``, where ``predictions``\n",
        "        has shape ``(MAX_LENGTH)`` and ``log_probs``\n",
        "        has shape ``(MAX_LENGTH)``.        \n",
        "    \"\"\"\n",
        "    assert 0.0 <= p and p <= 1.0, \"p needs to be between 0.0 and 1.0.\"\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # set the max. generation length as MAX_LENGTH. use <pad> tokens as placeholders for the tensor to store the decoded tokens.\n",
        "    predictions = (torch.ones(MAX_LENGTH)*PAD_IDX).int()\n",
        "    log_probs = torch.zeros(MAX_LENGTH)\n",
        "    \n",
        "    # encode the prefix given as a string into integer indices corresponding to their indices in the vocab set.\n",
        "    decoder_input =  torch.tensor([[BOS_IDX]+vocab.encode_token_seq(prefix.split())],device=device)\n",
        "    decoder_hidden = None\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for t in range(MAX_LENGTH):\n",
        "            decoder_logits, decoder_hidden = model.step(decoder_input, decoder_hidden)\n",
        "            decoder_logits = decoder_logits[0,-1,:] # selecting the last timestep (for encoding the prefix.) / get candidates; softmax added to compute joint lporb\n",
        "            output_dist = decoder_logits.softmax(-1)\n",
        "            \n",
        "            if p < 1.0:\n",
        "                sorted_logits, sorted_indices = torch.sort(decoder_logits, descending=True)\n",
        "                cumulative_probs = sorted_logits.softmax(-1).cumsum(-1)\n",
        "\n",
        "                # Remove tokens with cumulative probability above the threshold (token with 0 are kept)\n",
        "                sorted_indices_to_remove = cumulative_probs > p\n",
        "                if min_tokens_to_keep > 1:\n",
        "                    # Keep at least min_tokens_to_keep (set to min_tokens_to_keep-1 because we add the first one below)\n",
        "                    sorted_indices_to_remove[...,:min_tokens_to_keep] = 0\n",
        "                # Shift the indices to the right to keep also the first token above the threshold\n",
        "                sorted_indices_to_remove[...,1:] = sorted_indices_to_remove[...,:-1].clone()\n",
        "                sorted_indices_to_remove[...,0] = 0\n",
        "                # scatter sorted tensors to original indexing\n",
        "                indices_to_remove = sorted_indices_to_remove.scatter(0, sorted_indices, sorted_indices_to_remove)\n",
        "                if consistent_sampling:\n",
        "                    indices_to_remove[:, eos_idx].fill_(False)\n",
        "                decoder_logits[indices_to_remove] = filter_value\n",
        "                # topp is a sampling-based algorithm (non-deterministic approx. decoding algo.) \n",
        "                # therefore we use multinomial(1) to sample the most likely token from the predicted distribution.\n",
        "                \n",
        "            filtered_output_dist = decoder_logits.softmax(-1)\n",
        "            vocab_idx = filtered_output_dist.multinomial(1).item()\n",
        "            predictions[t] = vocab_idx\n",
        "            log_probs[t] = output_dist[vocab_idx].log()\n",
        "            \n",
        "            if vocab_idx == EOS_IDX:\n",
        "                break    \n",
        "            decoder_input = torch.tensor([[vocab_idx]],device=device)\n",
        "            \n",
        "    return (predictions, log_probs)"
      ],
      "metadata": {
        "id": "JSYKu7iiY8xa"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_p_sampling(prefix:str, p:float, filter_value=-float(\"Inf\"), min_tokens_to_keep=1):\n",
        "    \n",
        "    decoded_seq, log_probs = top_p_decode(model, prefix, vocab, p, filter_value=-float(\"Inf\"), min_tokens_to_keep=1)\n",
        "    decoded_seq = [token for token in vocab.decode_idx_seq(decoded_seq.tolist()) if token != '<pad>']\n",
        "    continuation = \" \".join(token for token in decoded_seq).strip()\n",
        "    log_probs = log_probs[log_probs.nonzero(as_tuple=True)[0]]\n",
        "    \n",
        "    print(f'\\n(Top-p sampling w/ p = {p} result):')\n",
        "    print(f' - (prefix)\\t:\\t{prefix}')\n",
        "    print(f' - (contin)\\t:\\t{continuation}')\n",
        "    print(f' - (joint-lprob):\\t{log_probs.sum():.5f}')"
      ],
      "metadata": {
        "id": "2kLMz9wwY8vX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('''(Original Sentence):''')\n",
        "print('''Due to low sales of Valkyria Chronicles II , Valkyria \\nChronicles III was not localized , but a \\\n",
        "fan translation compatible with the game 's expanded edition was released in 2014 .''')\n",
        "prefix = '''Due to low sales of Valkyria Chronicles II , Valkyria'''\n",
        "\n",
        "greedy(prefix)\n",
        "top_p_sampling(prefix,p=0.1) # nearly the same as greedy decoding.\n",
        "\n",
        "top_p_sampling(prefix,p=0.3)\n",
        "top_p_sampling(prefix,p=0.5)\n",
        "top_p_sampling(prefix,p=0.9)"
      ],
      "metadata": {
        "id": "q84budnBobAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c69ebb-84d4-4c65-c4d6-bacff786c766"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Original Sentence):\n",
            "Due to low sales of Valkyria Chronicles II , Valkyria \n",
            "Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 .\n",
            "\n",
            "(Greedy Decoding Result):\n",
            " - (prefix)\t\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (continuation)\t:\tChronicles III was released in the United States on November 7 , 2012 . <eos>\n",
            " - (log prob. of seq.)\t:\t-15.18872\n",
            "\n",
            "(Top-p sampling w/ p = 0.1 result):\n",
            " - (prefix)\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (contin)\t:\tChronicles III was released in the United States on November 18 , 2012 . <eos>\n",
            " - (joint-lprob):\t-15.19423\n",
            "\n",
            "(Top-p sampling w/ p = 0.3 result):\n",
            " - (prefix)\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (contin)\t:\tChronicles III was used for the Nintendo DS in 2005 . <eos>\n",
            " - (joint-lprob):\t-16.24324\n",
            "\n",
            "(Top-p sampling w/ p = 0.5 result):\n",
            " - (prefix)\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (contin)\t:\tChronicles III is a full theme of the player 's worst games . <eos>\n",
            " - (joint-lprob):\t-34.89100\n",
            "\n",
            "(Top-p sampling w/ p = 0.9 result):\n",
            " - (prefix)\t:\tDue to low sales of Valkyria Chronicles II , Valkyria\n",
            " - (contin)\t:\tChronicles II would be released in 1994 . <eos>\n",
            " - (joint-lprob):\t-14.68215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Je m'appelle Eugène. C'est un plaisir de vous rencontrer tous.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topp 0.1 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_dgyGMlXHHy",
        "outputId": "b3dc31aa-fc36-44dd-d136-89c59582b896"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Je ▁ m & ap os ; ▁appelle ▁ E ug è n e ▁. ▁C & ap os ; ▁est ▁un ▁pl a is ir ▁de ▁vous ▁rencont rer ▁tous ▁.\n",
            "W-0\t0.341\tseconds\n",
            "H-0\t-25.932525634765625\t▁I ' m ▁an ▁E ug u ad os ; ▁it ' s ▁called ▁E ug u ad ron es ; ▁C ap os ▁is ▁a ▁fold ▁to ▁meet ▁all ▁of ▁you .\n",
            "D-0\t-25.932525634765625\tI'm an Euguados; it's called Euguadrones; Capos is a fold to meet all of you.\n",
            "P-0\t-0.2068 -0.6965 -0.0524 -2.9469 -0.6793 -0.1209 -2.3098 -0.3038 -0.4581 -0.2459 -3.7061 -0.1199 -0.1139 -0.4450 -0.3710 -0.0510 -0.8154 -0.1097 -2.1538 -2.5481 -1.4510 -1.0011 -0.0124 -0.0141 -0.6653 -0.2707 -2.1254 -0.1458 -0.2012 -0.9410 -0.1495 -0.1554 -0.2308 -0.1147\n",
            "H-0\t-25.932525634765625\t▁I ' m ▁an ▁E ug u ad os ; ▁it ' s ▁called ▁E ug u ad ron es ; ▁C ap os ▁is ▁a ▁fold ▁to ▁meet ▁all ▁of ▁you .\n",
            "D-0\t-25.932525634765625\tI'm an Euguados; it's called Euguadrones; Capos is a fold to meet all of you.\n",
            "P-0\t-0.2068 -0.6965 -0.0524 -2.9469 -0.6793 -0.1209 -2.3098 -0.3038 -0.4581 -0.2459 -3.7061 -0.1199 -0.1139 -0.4450 -0.3710 -0.0510 -0.8154 -0.1097 -2.1538 -2.5481 -1.4510 -1.0011 -0.0124 -0.0141 -0.6653 -0.2707 -2.1254 -0.1458 -0.2012 -0.9410 -0.1495 -0.1554 -0.2308 -0.1147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Je m'appelle Eugène. C'est un plaisir de vous rencontrer tous.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topp 0.2 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwkfKNzMXYN5",
        "outputId": "864e0bbf-dde3-46e3-a194-de979df7738f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Je ▁m & ap os ; ▁appelle ▁E ug è ne ▁. ▁C & ap os ; ▁est ▁un ▁plais ir ▁de ▁vous ▁ren cont rer ▁tous ▁.\n",
            "W-0\t0.212\tseconds\n",
            "H-0\t-18.755224227905273\t▁I ' m ▁calling ▁E ug ne e . ▁C ap os ▁is ▁a ▁pleasure ▁to ▁tell ▁you ▁all .\n",
            "D-0\t-18.755224227905273\tI'm calling Eugnee. Capos is a pleasure to tell you all.\n",
            "P-0\t-0.4378 -0.4939 -0.0973 -3.1613 -0.4072 -0.0313 -3.3425 -0.8879 -1.2006 -2.2125 -0.0193 -0.0182 -1.7622 -0.4096 -0.8759 -0.4028 -0.2985 -1.1469 -0.3227 -1.1124 -0.1145\n",
            "H-0\t-22.193361282348633\t▁I ' m ▁called ▁E ug he us ; ▁C ap os ▁is ▁a ▁pleasure ▁to ▁tell ▁you ▁all .\n",
            "D-0\t-22.193361282348633\tI'm called Eugheus; Capos is a pleasure to tell you all.\n",
            "P-0\t-0.4378 -0.4939 -0.0973 -2.3741 -0.0618 -0.0330 -5.8878 -3.5558 -1.7497 -1.9061 -0.0271 -0.0160 -0.8160 -0.4413 -0.8537 -0.3285 -0.3250 -1.1586 -0.3337 -1.1823 -0.1137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Je m'appelle Eugène. C'est un plaisir de vous rencontrer tous.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topp 0.25 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYZHnHKrXaB-",
        "outputId": "8416b860-6d5e-49e0-d41d-413d6f9d9a79"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Je ▁m & ap o s ; ▁appelle ▁E ug è n e ▁. ▁C & ap os ; ▁est ▁un ▁plais ir ▁de ▁vous ▁rencont rer ▁tous ▁.\n",
            "W-0\t0.245\tseconds\n",
            "H-0\t-22.885295867919922\t▁I ' m ▁standing ▁up ; ▁E ug bra e ▁is ▁a ▁pleasure ▁to ▁meet ▁all ▁of ▁you .\n",
            "D-0\t-22.885295867919922\tI'm standing up; Eugbrae is a pleasure to meet all of you.\n",
            "P-0\t-0.4662 -0.5840 -0.0620 -4.0656 -2.3506 -0.2414 -1.5968 -0.0518 -6.0223 -0.7055 -2.3115 -0.7081 -1.3552 -0.3712 -0.2252 -1.2613 -0.0844 -0.1156 -0.1907 -0.1161\n",
            "H-0\t-26.16026496887207\t▁I ' m ▁m ic ap o os ; ▁E ug u ad ron ' s ▁a ▁pleasure ▁to ▁meet ▁all ▁of ▁you .\n",
            "D-0\t-26.16026496887207\tI'm micapoos; Euguadron's a pleasure to meet all of you.\n",
            "P-0\t-0.4662 -0.5840 -0.0620 -2.6757 -2.2653 -1.4961 -1.2496 -0.3794 -0.0991 -1.5097 -0.0448 -2.4425 -2.2922 -2.7948 -2.1790 -0.1207 -1.6274 -1.1816 -0.6168 -0.2142 -1.3314 -0.0830 -0.1190 -0.2111 -0.1148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Bonjour. Je m'appelle eugene et je suis ravi d'enseigner la PNL pour le programme AMMI 2022.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topp 0.1 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q3bpM6FXBbd",
        "outputId": "f7f87247-d7a9-4850-b0bc-b9269ed76aae"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Bon jour ▁. ▁Je ▁m & ap os ; ▁appelle ▁e ugen e ▁et ▁je ▁suis ▁ra vi ▁d & ap os ; ▁ense igner ▁la ▁P N L ▁pour ▁le ▁pro gram me ▁A M M I ▁20 2 2 ▁.\n",
            "W-0\t0.436\tseconds\n",
            "H-0\t-45.21653747558594\t▁H ell o . ▁I ' m ▁m ap os ▁called ▁e g os e , ▁and ▁I ' m ▁thr illed ▁to ▁teach ▁P N L ▁to ▁the ▁A M M I ▁program , ▁20 2 2 2 2 2 2 1.\n",
            "D-0\t-45.21653747558594\tHello. I'm mapos called egose, and I'm thrilled to teach PNL to the AMMI program, 202222221.\n",
            "P-0\t-0.4074 -0.7513 -0.0113 -0.8473 -0.2584 -0.4033 -0.0438 -2.3522 -1.9367 -1.5104 -1.3411 -0.0657 -5.1889 -1.5978 -0.7390 -0.9830 -0.1333 -0.1425 -0.3731 -0.0695 -1.4513 -0.0608 -0.5050 -0.1920 -0.9932 -0.0535 -0.1735 -0.8510 -1.3807 -2.5989 -0.0177 -0.2611 -0.5407 -1.6455 -1.9303 -0.8252 -0.5707 -0.4892 -0.7404 -1.2810 -2.2322 -3.4053 -3.7541 -0.1077\n",
            "H-0\t-47.432098388671875\t▁H ell o . ▁I ' m ▁m ap os ▁called ▁e mar os e , ▁and ▁I ' m ▁thr illed ▁to ▁teach ▁P N L ▁to ▁the ▁A M M I ▁program , ▁20 2 2 2 2 2 2 1.\n",
            "D-0\t-47.432098388671875\tHello. I'm mapos called emarose, and I'm thrilled to teach PNL to the AMMI program, 202222221.\n",
            "P-0\t-0.4074 -0.7513 -0.0113 -0.8473 -0.2584 -0.4033 -0.0438 -2.3522 -1.9367 -1.5104 -1.3411 -0.0657 -5.1494 -2.9358 -1.8767 -0.8706 -0.1339 -0.1422 -0.3698 -0.0709 -1.4485 -0.0598 -0.5242 -0.1875 -0.9258 -0.0533 -0.1683 -0.8409 -1.3323 -2.5981 -0.0177 -0.2651 -0.5210 -1.5646 -1.9141 -0.8102 -0.5909 -0.4935 -0.7609 -1.2997 -2.2714 -3.4127 -3.7855 -0.1078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "eLy8iLxaHcsL",
        "outputId": "be60c4d9-4a80-4a99-bc77-206581162a6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Bon jour ▁. ▁Je ▁m & ap os ; ▁app elle ▁eu gen e ▁et ▁je ▁suis ▁ra vi ▁d & ap os ; ▁ense igner ▁la ▁P N L ▁pour ▁le ▁programme ▁A M M I ▁20 2 2 ▁.\n",
            "W-0\t0.381\tseconds\n",
            "H-0\t-30.621183395385742\t▁H ell o . ▁I ' m ▁a ▁m ic ron , ▁and ▁I ' m ▁happy ▁to ▁teach ▁P N L ▁to ▁the ▁program ▁for ▁the ▁I M M F ▁20 2 2 ▁program .\n",
            "D-0\t-30.621183395385742\tHello. I'm a micron, and I'm happy to teach PNL to the program for the IMMF 2022 program.\n",
            "P-0\t-0.3891 -0.7919 -0.0113 -0.8222 -0.3276 -0.9381 -0.0667 -2.1238 -2.2481 -1.9542 -0.4945 -1.9230 -0.1503 -0.1320 -0.4130 -0.0777 -1.7772 -0.1469 -0.2384 -1.2689 -0.0898 -0.3649 -1.1514 -0.7198 -1.7051 -2.2494 -0.9751 -1.2147 -0.0050 -0.9100 -1.4662 -1.8435 -0.0576 -0.7968 -0.5539 -0.1205 -0.1025\n",
            "H-0\t-30.621183395385742\t▁H ell o . ▁I ' m ▁a ▁m ic ron , ▁and ▁I ' m ▁happy ▁to ▁teach ▁P N L ▁to ▁the ▁program ▁for ▁the ▁I M M F ▁20 2 2 ▁program .\n",
            "D-0\t-30.621183395385742\tHello. I'm a micron, and I'm happy to teach PNL to the program for the IMMF 2022 program.\n",
            "P-0\t-0.3891 -0.7919 -0.0113 -0.8222 -0.3276 -0.9381 -0.0667 -2.1238 -2.2481 -1.9542 -0.4945 -1.9230 -0.1503 -0.1320 -0.4130 -0.0777 -1.7772 -0.1469 -0.2384 -1.2689 -0.0898 -0.3649 -1.1514 -0.7198 -1.7051 -2.2494 -0.9751 -1.2147 -0.0050 -0.9100 -1.4662 -1.8435 -0.0576 -0.7968 -0.5539 -0.1205 -0.1025\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Bonjour. Je m'appelle eugene et je suis ravi d'enseigner la PNL pour le programme AMMI 2022.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topp 0.2 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "aO0-eeJGHcsL",
        "outputId": "68ffeb33-e317-47dd-c8ad-b8d0e5f1edde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Bon j our ▁. ▁Je ▁m & ap os ; ▁a pp elle ▁eu gen e ▁et ▁je ▁suis ▁ra v i ▁d & ap os ; ▁ense igner ▁la ▁P N L ▁ p our ▁l e ▁programme ▁A M M I ▁20 2 2 ▁.\n",
            "W-0\t0.412\tseconds\n",
            "H-0\t-46.98944091796875\t▁Good ▁even ing . ▁I ▁am ▁m ap os a ▁E v ident ▁and ▁I ▁am ▁thr illed ▁with ▁a ▁P N L ▁heavy ▁program ▁A M M I M 2 2 .\n",
            "D-0\t-46.98944091796875\tGood evening. I am maposa Evident and I am thrilled with a PNL heavy program AMMIM22.\n",
            "P-0\t-1.0627 -3.6331 -0.0583 -1.3932 -0.3154 -1.4561 -1.5502 -2.0208 -0.5425 -1.9669 -3.3551 -2.6062 -3.8860 -1.3706 -0.2720 -0.5632 -0.5789 -0.1347 -0.9946 -1.6045 -1.6290 -0.1761 -0.2848 -5.3320 -0.6662 -0.6454 -0.0338 -0.4980 -0.4195 -2.0986 -1.7220 -1.9814 -2.0333 -0.1044\n",
            "H-0\t-59.7772331237793\t▁Good ▁job . ▁I ▁am ▁m ap os a ▁was ▁a gen cies , ▁and ▁I ▁am ▁thr illed ▁with ▁the ▁P N L : ▁I ▁am ▁a ▁l oud ▁program ▁A M M I , ▁20 2 2 nd ry .\n",
            "D-0\t-59.7772331237793\tGood job. I am maposa was agencies, and I am thrilled with the PNL: I am a loud program AMMI, 2022ndry.\n",
            "P-0\t-1.0627 -4.2890 -1.6276 -0.4153 -1.6990 -1.5164 -2.0875 -0.4665 -1.9428 -3.4010 -1.8346 -5.1165 -0.2981 -0.9707 -0.1631 -0.1404 -0.6720 -0.6053 -0.0933 -0.9420 -1.9181 -1.0901 -0.1306 -0.3670 -2.4449 -1.7990 -0.9924 -1.5656 -2.2809 -0.2624 -2.5655 -0.3506 -0.0258 -0.2650 -1.0449 -3.3991 -0.8770 -0.0979 -1.1574 -3.1484 -4.0922 -0.4471 -0.1118\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Bonjour. Je m'appelle eugene et je suis ravi d'enseigner la PNL pour le programme AMMI 2022.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topp 0.25 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Bonjour, je m'appelle Stephen Kiilu. Je suis étudiant à AIMS Sénégal.\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 10.0 --max-len-b 100 \\\n",
        "    --sampling --sampling-topp 0.35 --sentencepiece-enable-sampling \\\n",
        "    --nbest 2 --beam 2 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxDe8NDikQQw",
        "outputId": "e3acab23-0274-44db-e376-a3afd88d2376"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Bon jour ▁, ▁je ▁m & ap o s ; ▁appelle ▁S te p hen ▁K i il u ▁. ▁Je ▁suis ▁étud iant ▁à ▁ A I MS ▁S é né gal ▁.\n",
            "W-0\t0.370\tseconds\n",
            "H-0\t-18.2369441986084\t▁H ell o , ▁I ' m ▁S te p hen ▁K i il u . ▁I ' m ▁a ▁student ▁at ▁ A I MS ▁S é gal .\n",
            "D-0\t-18.2369441986084\tHello, I'm Stephen Kiilu. I'm a student at AIMS Ségal.\n",
            "P-0\t-0.3433 -0.5646 -0.0114 -0.4138 -0.3110 -0.2803 -0.0397 -3.8621 -0.5117 -0.0034 -0.0166 -0.0337 -0.1217 -0.0857 -0.0171 -1.8452 -0.2210 -0.1893 -0.0501 -0.1180 -0.1468 -0.2642 -0.6899 -1.6445 -0.9737 -1.3247 -0.0354 -2.4672 -1.4548 -0.0836 -0.1127\n",
            "H-0\t-26.16551399230957\t▁H ell o , ▁I ' m ▁m ap o os ; ▁S te p hen ▁K i il u ; ▁I ' m ▁a ▁student ▁at ▁ A I MS ▁S es qu ake .\n",
            "D-0\t-26.16551399230957\tHello, I'm mapoos; Stephen Kiilu; I'm a student at AIMS Sesquake.\n",
            "P-0\t-0.3433 -0.5646 -0.0114 -0.4138 -0.3110 -0.2803 -0.0397 -3.2170 -0.9980 -0.3421 -0.3468 -0.9841 -1.1604 -0.4249 -0.0040 -0.0185 -0.0339 -0.1099 -0.0601 -0.0130 -2.3946 -0.1311 -0.2022 -0.0521 -0.1417 -0.1227 -0.2566 -0.5688 -1.6516 -0.7134 -1.1687 -0.0519 -3.1759 -1.3806 -4.1930 -0.1691 -0.1147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgpZIzeqx5qc"
      },
      "source": [
        "Note: except ancestral sampling, all of the decoding strategies that we have covered so far are all **approximate decoding algorithms**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0PUQPFLCvR9"
      },
      "source": [
        "# Part 2: Curses of Approximate Decoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The encoder-decoder + approximate generation framework, while looking good on paper, struggles from degenerate outputs (which do not make any sense in the context of the problem). \n",
        "\n",
        "Degeneracies are model-defined problems and cannot be overcome by scaling or increasing the number of parameters in the model. We need to come up with architecture/training changes to control this issue.\n",
        "\n",
        "Nowadays, we do not have all the **remedies** for the problem of corrupted distribution learned by the model. \n",
        "\n",
        "We, however, can utilize some heuristic **tricks** that alleviate this problems during the generation stage without modyfying the internal distribution."
      ],
      "metadata": {
        "id": "0i5_y_kUcM2J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0Jv_-NdNEAt"
      },
      "source": [
        "## 2.1) Infinite-length sequences:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formal explanation of why models assign non-zero probabilities to infinite sequences (we call such models inconsistent): [Paper](https://arxiv.org/pdf/2002.02492.pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "x7t6PesUcM2K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "8U3v8hicL61-"
      },
      "outputs": [],
      "source": [
        "!pip install transformers &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "h34yjXA22v-F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "2b643c5f9f2c496d89442eae620c5776",
            "6b42d711555a4411b0d42488729e8256",
            "6ad1abd312f140c389f262106f9c7156",
            "3e8a6697f7b5440d9c1a77a994cf0b89",
            "0ede99c142d44a349a7408b0f15d3b1e",
            "d9b29157b3eb402cba6e851adb7c3aa4",
            "4eeb2b4141df47fa911020a186b5daa0",
            "a0f2d41281f049e9be727cb316cf3550",
            "d462afe17fd7406b9f01276e3b720495",
            "f6508da61dbe497bbf4c00d761c9cd04",
            "95e5c61b03fb49d396a00c06ea1bb043",
            "9b386d0a3ef34844acd1db0d57adaa49",
            "e1d5262840314db9bbb3e355153bbd35",
            "fa2cc1a6c450403193b66dde7ae9ac82",
            "9c16b34475a04bf2a04634c1b8da8acc",
            "9a870d56790f4f08804e3ddf62098224",
            "883c7b850e7d4278950fc9ddbd9bfe0d",
            "06ee500b3d6d4fa59e32ee8528952bc9",
            "73a27099528747a9bf7c015a69c009ee",
            "bf6b2652a00d453ca9da39081a9bd0e3",
            "cc5023b78c7a460eaf1378e47976c3f1",
            "9ed9ac5af51d4137ab62f8b8ed64efe3",
            "d5ca46abe1c9449f8cb219c03e27954e",
            "517412aa83874dcfada3806c2185c4fc",
            "ab9bc6e6e89841968fda99567d3ce71c",
            "98943bdc08624ac3b41fb1bc35c485af",
            "4249890508d144f59d1df54552f56e32",
            "07ac260cb38c48478c0845571337a365",
            "f4a249f3c2ae46d797bccf2074517af9",
            "283d3438bc504ef6858724dd66d61d2a",
            "bbf7092108ed441393078c6b1c866037",
            "9479f49f27f648319d8cb9f8e4241b4f",
            "e05206ab890d4b7c9e9bc0a5e76c36ce",
            "a3ebd30ef736466f96ee33b57504c8e0",
            "b7e5c80b4b4741aeaa7c546c6bc4141c",
            "6247806e25bd4820be23ba73a2f97889",
            "57dde0446ce844fb97f8be8b705633ef",
            "09c91683dbac4ac69b24566c0afb5f5a",
            "e61c21f7f36942a3b7aa1b5c5fce83ea",
            "8ff7af986ba641b98a233a10a9ff8312",
            "1259da7ec8944f24bbcc765537edf2ae",
            "78dbeebd864242899a81b117f719bc84",
            "00a88d1d0f6e4607b1da28a327b3dfc3",
            "f395dfdadd544a4cbb9e25fd20e1f912"
          ]
        },
        "outputId": "eb95dad1-7f7b-44d0-8483-07dbafe618cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b643c5f9f2c496d89442eae620c5776"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b386d0a3ef34844acd1db0d57adaa49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5ca46abe1c9449f8cb219c03e27954e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3ebd30ef736466f96ee33b57504c8e0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2Tokenizer\n",
        ")\n",
        "\n",
        "device = torch.device('cpu') if not torch.cuda.is_available() else torch.device('cuda:0')\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fT2EvRWL2ytc"
      },
      "outputs": [],
      "source": [
        "max_length = 500\n",
        "\n",
        "model.config.max_length=max_length\n",
        "\n",
        "prefix = 'My favorite food is'\n",
        "inp = torch.tensor([tokenizer.encode(prefix)], device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LIbcnc32wpO",
        "outputId": "4fcc4efc-df3f-410d-fbc3-6d24dd6f0b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "out = model.generate(\n",
        "    input_ids=inp,\n",
        "    do_sample=False,\n",
        "    max_length=max_length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "RWxFGOql3Yv5",
        "outputId": "47ef19e8-2886-4773-fdf5-9b0959bf95fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My favorite food is the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the chicken. I love the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "tokenizer.decode(out[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTKhaUyt23cR",
        "outputId": "c085fd46-34fe-494f-b66d-6e3b5293db8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "prefix = 'GPT-2 is known for generating a fluent, human-like prose and it is'\n",
        "inp = torch.tensor([tokenizer.encode(prefix)], device=device)\n",
        "\n",
        "out = model.generate(\n",
        "    input_ids=inp,\n",
        "    do_sample=False,\n",
        "    max_length=max_length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "aAvRbuli4p6Q",
        "outputId": "428c365d-f5ec-4aba-8b8a-83a1fee38c30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GPT-2 is known for generating a fluent, human-like prose and it is a great way to get your hands on a new language.\\n\\nThe first thing you need to do is to download the latest version of the language.\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n\\nDownload the latest version of the language\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "tokenizer.decode(out[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5yFn7KPHcsN"
      },
      "source": [
        "### How to spot\n",
        "\n",
        "Infinite translation are typically repetitive. Thus, ngram repetition\n",
        "\n",
        "$$\n",
        "\\text{seq-rep-n} = 1.0 - \\frac{|\\text{unique n-grams}(\\textbf{x}_{k+1:k+N}|)}{|\\text{n-grams}|}\n",
        "$$\n",
        "\n",
        "We do not nessessarily want this to be zero, but a good model avoids large values."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "from nltk import ngrams\n",
        "\n",
        "def ngram_metrics(token_list):\n",
        "    stats = defaultdict(float)\n",
        "    for n in range(1, 5):\n",
        "        ngs = [ng for ng in ngrams(token_list, n)]\n",
        "        counter = Counter([ng for ng in ngrams(token_list, n)])\n",
        "        stats['pct_repeat_%dgrams' % n] = 1.0 - len(counter)/len(ngs)\n",
        "    return stats"
      ],
      "metadata": {
        "id": "PFZc1VXaYQEQ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_metrics(out[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6CfR0plY8uw",
        "outputId": "ceadec30-6d45-4aa7-f772-8f85d6727a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(float,\n",
              "            {'pct_repeat_1grams': 0.922,\n",
              "             'pct_repeat_2grams': 0.8997995991983968,\n",
              "             'pct_repeat_3grams': 0.8955823293172691,\n",
              "             'pct_repeat_4grams': 0.8913480885311871})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW6vA767OI-v",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "Even for the large language models, these degeneracies still persists!\n",
        "\n",
        "### Tricks:\n",
        "\n",
        "Just set the maximum length! Generate end-of-sequence if generator reached max length.\n",
        "\n",
        "How to choose the max length parameter for a conditional sequence modeling?\n",
        "\n",
        "For translation we believe that source and reference should have similar length. Moreover, linear model is enough to learn the correct length mapping.\n",
        "\n",
        "Thus, we typically use max_length = **1.2|x| + 10**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = 'GPT-2 is known for generating a fluent, human-like prose and it is'\n",
        "inp = torch.tensor([tokenizer.encode(prefix)], device=device)\n",
        "\n",
        "source_length = inp.shape[1]\n",
        "max_length = 1.2 * source_length + 10\n",
        "\n",
        "out = model.generate(\n",
        "    input_ids=inp,\n",
        "    do_sample=False,\n",
        "    max_length=max_length\n",
        ")\n",
        "tokenizer.decode(out[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "58e8e375-e252-4135-a1b7-56fdfd961f4e",
        "id": "6RjcC9NmcM2O"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GPT-2 is known for generating a fluent, human-like prose and it is a great way to get your hands on a new language.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remedies: \n",
        "\n",
        "* Unlikelihood loss: [Paper](https://arxiv.org/pdf/1908.04319.pdf)\n",
        "\n",
        "* Oversmoothing-terminal: stay tuned for the research talk on day 4"
      ],
      "metadata": {
        "id": "EFO2lf2ZYoH6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVVymjgFNUAf"
      },
      "source": [
        "## 2.2) Premature sequences:\n",
        "\n",
        "* Known as the \"beam search curse\"\n",
        "* Extremely short translations are generated when using large beam sizes\n",
        "\n",
        "Why?\n",
        "\n",
        "We model the probability of the end-of-sequence token incorrectly. Beam search with larger beam size tests more tokens on earlier timesteps."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Note May 15, 2023.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "jcgyO3pucM2P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "loQul1xUHcsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38bcc25c-0f9a-4816-ad67-6ccd082b095f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁sal ut ▁mon ▁nom ▁est ▁ma x ▁, ▁je ▁suis ▁ass istant ▁d & ap os ; ▁enseign ement ▁pour ▁le ▁cours ▁de ▁ma î tr ise ▁af ric aine ▁en ▁N L P\n",
            "W-0\t1.355\tseconds\n",
            "H-0\t-14.9732027053833\t▁And ▁my ▁name ▁is ▁a ▁ma x .\n",
            "D-0\t-14.9732027053833\tAnd my name is a max.\n",
            "P-0\t-2.1942 -0.6702 -0.0387 -0.4507 -1.8962 -1.0279 -0.0368 -3.4144 -5.2441\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"salut mon nom est max, je suis assistant d'enseignement pour le cours de maîtrise africaine en NLP\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.2 --max-len-b 10 \\\n",
        "    --beam 1000 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "GaNL3moQHcsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87475969-d54b-4456-a8ef-fd0a2b4c9f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁sal ut ▁mon ▁nom ▁est ▁ma x ▁, ▁je ▁suis ▁ass istant ▁d & ap os ; ▁enseign ement ▁pour ▁le ▁cours ▁de ▁ma î tr ise ▁af ric aine ▁en ▁N L P\n",
            "W-0\t0.286\tseconds\n",
            "H-0\t-20.043455123901367\t▁And ▁my ▁name ▁is ▁a ▁ma x , ▁and ▁I ' m ▁an ▁ass istant ▁for ▁African ▁master y ▁in ▁N L P .\n",
            "D-0\t-20.043455123901367\tAnd my name is a max, and I'm an assistant for African mastery in NLP.\n",
            "P-0\t-2.1942 -0.6702 -0.0387 -0.4507 -1.8962 -1.0279 -0.0368 -0.8203 -0.4326 -0.2583 -0.4901 -0.0514 -2.6032 -1.3140 -0.1225 -2.5718 -1.5298 -0.2299 -0.9448 -1.2758 -0.0591 -0.0223 -0.1932 -0.7024 -0.1072\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"salut mon nom est max, je suis assistant d'enseignement pour le cours de maîtrise africaine en NLP\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.2 --max-len-b 10 \\\n",
        "    --beam 5 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --unnormalized --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84GymLioHcsO"
      },
      "source": [
        "### How to spot\n",
        "\n",
        "* Length Ratio:\n",
        "\n",
        "$$\n",
        "\\text{LR} = \\frac{|\\textbf{y}_{\\text{ref}}|}{|\\textbf{y}_{\\text{gen}}|}\n",
        "$$\n",
        "\n",
        "Be aware, that LR is token-level, not word-level. Thus, for empty translation the LR denominator equals 1 (empty translation consists of the only token, end-of-sequence).\n",
        "\n",
        "Corpus-level LR is typically computed as \n",
        "\n",
        "$$\n",
        "\\text{LR} = \\sum_{i=1}^N\\frac{|\\textbf{y}^n_{\\text{ref}}|}{|\\textbf{y}^n_{\\text{gen}}|}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def length_ratio(candidate, reference):\n",
        "    return len(reference.split()) / len(candidate.split())"
      ],
      "metadata": {
        "id": "NVJ11b8FaSo6"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length_ratio('▁And ▁my ▁name ▁is ▁a ▁ma x . <eos>', 'And my name is a max, and I\\'m an assistant for African mastery in NLP. <eos>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOPWj8cxadwQ",
        "outputId": "12c8f53c-2310-47c0-e7a7-0d2d645f209e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* BLEU\n",
        "\n",
        "BLEU has a brevity penalty as well! It penalizes the extremely short sequences.\n",
        "\n",
        "$$\n",
        "BP=\\exp\\left(1-\\frac{||y_{\\text{ref}}||}{||y_{\\text{gen}}||}\\right)\\text{, bit only if } ||y_{\\text{ref}}|| < ||y_{\\text{gen}}||\n",
        "$$\n",
        "\n",
        "$||y_{\\text{ref}}||$ and $||y_{\\text{gen}}||$ are **word** counts, not token counts."
      ],
      "metadata": {
        "id": "UrhFxzg-aRWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "sacrebleu.corpus_bleu(['And my name is a max.'], [['And my name is a max, and I\\'m an assistant teacher for the African mastery course in PNL.']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD2R7ZVrWSxQ",
        "outputId": "cfa77e77-c558-4a97-abd0-768213b7d836"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BLEU = 13.13 100.0/83.3/80.0/75.0 (BP = 0.156 ratio = 0.350 hyp_len = 7 ref_len = 20)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "SGUHb5UYHcsO"
      },
      "source": [
        "### Tricks\n",
        "\n",
        " * Length normalization (penalize the probability for short sequences):\n",
        "\n",
        "$$\n",
        "\\color{red}{\\frac{1}{|\\textbf{y}_{gen}|}}\\sum_{i=1}^{|\\textbf{y}_{gen}|} \\log p(y_t | y_{<t})\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "lL1OWPlGHcsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900dc6e2-3400-4d67-d7cd-a6ae9f52f433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁sal ut ▁mon ▁nom ▁est ▁ma x ▁, ▁je ▁suis ▁ass istant ▁d & ap os ; ▁enseign ement ▁pour ▁le ▁cours ▁de ▁ma î tr ise ▁af ric aine ▁en ▁P N L\n",
            "W-0\t1.364\tseconds\n",
            "H-0\t-0.7553730010986328\t▁And ▁my ▁name ▁is ▁a ▁ma x , ▁and ▁I ' m ▁an ▁ass istant ▁teacher ▁for ▁the ▁African ▁master y ▁course ▁in ▁P N L .\n",
            "D-0\t-0.7553730010986328\tAnd my name is a max, and I'm an assistant teacher for the African mastery course in PNL.\n",
            "P-0\t-2.1503 -0.6402 -0.0393 -0.4528 -1.8780 -1.0858 -0.0335 -0.8115 -0.4287 -0.2614 -0.4921 -0.0519 -2.6163 -1.2925 -0.1155 -2.9293 -0.7830 -0.9746 -1.1706 -0.3615 -1.0977 -0.2213 -0.3683 -0.0737 -0.0578 -0.5497 -0.1004 -0.1127\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"salut mon nom est max, je suis assistant d'enseignement pour le cours de maîtrise africaine en PNL\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.2 --max-len-b 10 \\\n",
        "    --beam 1000 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Length penalty when normalization does not help:\n",
        "\n",
        "$$\n",
        "\\frac{1}{|\\textbf{y}_{gen}|^{\\color{red}{lp}}}\\sum_{i=1}^{|\\textbf{y}_{gen}|} \\log p(y_t | y_{<t})\n",
        "$$\n",
        "\n",
        "When $lp=1.0$ we use standard normalization. For $lp < 1.0$ the model favors shorter translations, for $lp > 1.0$ model prefers longer translations.\n"
      ],
      "metadata": {
        "id": "baSNV7n3TfLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Un transformateur est un modèle d'apprentissage en profondeur qui adopte le mécanisme de l'auto-attention, en pondérant différemment l'importance de chaque partie des données d'entrée. \\\n",
        "      Il est principalement utilisé dans les domaines du traitement du langage naturel (TAL)[1] et de la vision par ordinateur (CV).[2] \\\n",
        "      Comme les réseaux de neurones récurrents (RNN), les transformateurs sont conçus pour traiter des données d'entrée séquentielles, telles que le langage naturel\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.2 --max-len-b 10 \\\n",
        "    --beam 1000 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj72SnW2UDua",
        "outputId": "5b8dc3e9-1ab0-477e-8e30-3597afea560d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Un ▁transform ateur ▁est ▁un ▁modèle ▁d & ap os ; ▁app rentissage ▁en ▁profonde ur ▁qui ▁ad op te ▁le ▁mécan isme ▁de ▁l & ap os ; ▁aut o ▁ @ - @ ▁attention ▁, ▁en ▁p ond ér ant ▁diff é re mment ▁l & ap os ; ▁importance ▁de ▁chaque ▁partie ▁des ▁données ▁d & ap os ; ▁ent rée ▁. ▁Il ▁est ▁princip alement ▁utilisé ▁dans ▁les ▁dom aines ▁du ▁traitement ▁du ▁langage ▁nature l ▁( ▁T A L ▁ ) ▁& # 9 1 ; ▁1 ▁& # 9 3 ; ▁et ▁de ▁la ▁vision ▁par ▁ordinateur ▁( ▁C V ▁ ) ▁. ▁& # 9 1 ; ▁2 ▁& # 9 3 ; ▁Comme ▁les ▁rése aux ▁de ▁neur ones ▁réc ur r ents ▁( ▁R N N ▁ ) ▁, ▁les ▁transform ateurs ▁sont ▁con ç us ▁pour ▁traiter ▁des ▁données ▁d & ap os ; ▁ent rée ▁séqu ent ie lles ▁, ▁tell es ▁que ▁le ▁langage ▁nature l\n",
            "W-0\t12.048\tseconds\n",
            "H-0\t-1.0138461589813232\t▁A ▁transform ative ▁is ▁a ▁model ▁of ▁learning ▁deep ▁inside ▁that ▁adapt s ▁the ▁mechan ism ▁of ▁the ▁self - d ou bt ▁mechan ism , ▁by ▁lay ing ▁in ▁a ▁different ▁way , ▁by ▁different i ating ▁the ▁em ph as is ▁of ▁every ▁part ▁of ▁the ▁input ▁data , ▁and ▁it ' s ▁mostly ▁used ▁in ▁dom ains ▁of ▁natural ▁language ▁process ing ▁T A L ▁ # 9 1 ▁and ▁computer ▁vision ▁by ▁C V V ▁ # 1 4, ▁is ▁transform ed ▁by ▁the ▁computer\n",
            "D-0\t-1.0138461589813232\tA transformative is a model of learning deep inside that adapts the mechanism of the self-doubt mechanism, by laying in a different way, by differentiating the emphasis of every part of the input data, and it's mostly used in domains of natural language processing TAL #91 and computer vision by CVV #14, is transformed by the computer\n",
            "P-0\t-0.2858 -0.3999 -0.0853 -1.8490 -0.1583 -0.5677 -0.1171 -0.2453 -0.9566 -1.3711 -0.3792 -3.2012 -0.0730 -0.6011 -0.0532 -0.2063 -0.1805 -1.5076 -0.4986 -0.0379 -4.8048 -1.9246 -0.0767 -0.5977 -0.1688 -1.0737 -0.7746 -1.8072 -0.4237 -2.6214 -0.6853 -0.2027 -0.1638 -2.7261 -2.3147 -1.3998 -0.9768 -0.0973 -0.2789 -4.9976 -0.6046 -0.0358 -0.1614 -1.5975 -1.0220 -0.7827 -0.1457 -0.4372 -1.0008 -0.8085 -2.5181 -0.8857 -1.2731 -0.4109 -0.0904 -1.1439 -0.2091 -0.2868 -2.2257 -0.3045 -0.2943 -0.7324 -0.2481 -1.2788 -0.1108 -1.3490 -0.0517 -0.0963 -2.2724 -0.1076 -1.6422 -0.6623 -1.0478 -0.0762 -0.0103 -0.9857 -0.3948 -3.3374 -1.0526 -1.0792 -0.2897 -1.1486 -1.4669 -5.8293 -0.9531 -0.1939 -0.9335 -1.2521 -1.0123 -4.5008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"Un transformateur est un modèle d'apprentissage en profondeur qui adopte le mécanisme de l'auto-attention, en pondérant différemment l'importance de chaque partie des données d'entrée. \\\n",
        "      Il est principalement utilisé dans les domaines du traitement du langage naturel (TAL)[1] et de la vision par ordinateur (CV).[2] \\\n",
        "      Comme les réseaux de neurones récurrents (RNN), les transformateurs sont conçus pour traiter des données d'entrée séquentielles, telles que le langage naturel\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.2 --max-len-b 10 \\\n",
        "    --beam 1000 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --lenpen 3 --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKp6okebKCvP",
        "outputId": "e44e4457-d15a-40c3-b60b-99127e9d49c0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁Un ▁transform ateur ▁est ▁un ▁modèle ▁d & ap os ; ▁app rentissage ▁en ▁profonde ur ▁qui ▁ad op te ▁le ▁mécan isme ▁de ▁l & ap os ; ▁aut o ▁ @ - @ ▁attention ▁, ▁en ▁p ond ér ant ▁diff é re mment ▁l & ap os ; ▁importance ▁de ▁chaque ▁partie ▁des ▁données ▁d & ap os ; ▁ent rée ▁. ▁Il ▁est ▁princip alement ▁utilisé ▁dans ▁les ▁dom aines ▁du ▁traitement ▁du ▁langage ▁nature l ▁( ▁T A L ▁ ) ▁& # 9 1 ; ▁1 ▁& # 9 3 ; ▁et ▁de ▁la ▁vision ▁par ▁ordinateur ▁( ▁C V ▁ ) ▁. ▁& # 9 1 ; ▁2 ▁& # 9 3 ; ▁Comme ▁les ▁rése aux ▁de ▁neur ones ▁réc ur r ents ▁( ▁R N N ▁ ) ▁, ▁les ▁transform ateurs ▁sont ▁con ç us ▁pour ▁traiter ▁des ▁données ▁d & ap os ; ▁ent rée ▁séqu ent ie lles ▁, ▁tell es ▁que ▁le ▁langage ▁nature l\n",
            "W-0\t12.188\tseconds\n",
            "H-0\t-7.098245987435803e-05\t▁A ▁transform ative ▁is ▁a ▁model ▁of ▁learning ▁deep ▁inside ▁that ▁adapt s ▁the ▁mechan ism ▁of ▁the ▁self - d ou bt ▁mechan ism , ▁by ▁lay ing ▁in ▁a ▁different ▁way ▁the ▁em ph as is ▁on ▁each ▁part ▁of ▁the ▁input ▁data , ▁and ▁it ' s ▁mostly ▁used ▁in ▁dom ains ▁of ▁natural ▁language ▁process ing ▁T A L ▁ # 9 1 ▁and ▁computer ▁vision ▁by ▁C ape V ▁ # 1 : ▁ # 1 N 1 3 ▁are ▁transform ed ▁by ▁the ▁language ▁of ▁rec ur rent ▁neurons , ▁and ▁the ▁computer ▁vision ▁is ▁transform ed ▁by ▁R ap ital ized , ▁and ▁the ▁computer ▁vision ▁is ▁transform ed ▁to ▁treat ▁the ▁natural ▁language\n",
            "D-0\t-7.098245987435803e-05\tA transformative is a model of learning deep inside that adapts the mechanism of the self-doubt mechanism, by laying in a different way the emphasis on each part of the input data, and it's mostly used in domains of natural language processing TAL #91 and computer vision by CapeV #1: #1N13 are transformed by the language of recurrent neurons, and the computer vision is transformed by Rapitalized, and the computer vision is transformed to treat the natural language\n",
            "P-0\t-0.2858 -0.3999 -0.0853 -1.8490 -0.1583 -0.5677 -0.1171 -0.2453 -0.9566 -1.3711 -0.3792 -3.2012 -0.0730 -0.6011 -0.0532 -0.2063 -0.1805 -1.5076 -0.4986 -0.0379 -4.8048 -1.9246 -0.0767 -0.5977 -0.1688 -1.0737 -0.7746 -1.8072 -0.4237 -2.6214 -0.6853 -0.2027 -0.1638 -2.4797 -5.4653 -0.3703 -0.0324 -0.2267 -0.6911 -0.6793 -1.4107 -0.1475 -0.3652 -1.5111 -0.7134 -2.4768 -0.6561 -1.1540 -0.4285 -0.0905 -1.1191 -0.2360 -0.2913 -2.4855 -0.5402 -0.2391 -0.6573 -0.2881 -1.3496 -0.1147 -1.3016 -0.0599 -0.1049 -1.9731 -0.1169 -1.2956 -0.5235 -0.3839 -0.0911 -0.0084 -1.5647 -0.3823 -6.2514 -0.0966 -0.2547 -0.4094 -0.8209 -2.9738 -1.5009 -0.1085 -1.0909 -2.9346 -0.5356 -1.2979 -3.7552 -0.6225 -0.3479 -1.5161 -0.9960 -1.6744 -0.2998 -3.1303 -2.0340 -0.8972 -1.2729 -1.0994 -1.7343 -1.3904 -1.6252 -0.0242 -1.4719 -0.1063 -0.1329 -1.8144 -0.8942 -0.8300 -1.1894 -0.2122 -2.3236 -1.6145 -0.2983 -2.3794 -0.5707 -1.4844 -0.1148 -0.2011 -3.3825 -0.6222 -2.7759 -0.4413 -0.6258 -2.5871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-ranking helps to tackle the length degeneracy problems.\n",
        "\n",
        "* Use a well-trained language model for the target language\n",
        "* Estimate the probability of every candidate from beam search under the language model\n",
        "* Re-rank them accodring to the LM's probability\n",
        "* Well-formed sequences should help to overcome the issue"
      ],
      "metadata": {
        "id": "hP0OUY0JcM2V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giK9A9UqOUoU"
      },
      "source": [
        "###Remedy: \"Non-terminal oversmoothing loss\"\n",
        "\n",
        "* From \"Characterizing and addressing the issue of oversmoothing in neural autoregressive sequence modeling\" (Kulikov, Eremeev, Cho 2021) [(Paper)](https://arxiv.org/abs/2112.08914)\n",
        "\n",
        "* Effective in fixing the beam search curse in the machine translation setting!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5e32iL7NWeN"
      },
      "source": [
        "## 2.3) Hallucination:\n",
        "\n",
        "* Due to the inherent uncertainty in natural language:\n",
        "  * For translation, there are multiple candidate hypotheses that are both well-formed and valid.\n",
        "\n",
        "* This is where the bias inherent in the data creeps up.\n",
        "* [ALPS 2022 - Machine Translation and Degeneracies (1)](https://www.youtube.com/watch?v=hoecPa9l2no&t=327s): amazing talk by Prof. Cho that demonstrating and explaining the existence and potential dangers of hallucination in machine translation.\n",
        "* Analyzing Uncertainty in Neural Machine Translation (Ott et. al. 2018) [(Paper)](https://arxiv.org/abs/1803.00047)\n",
        "\n",
        "* Even Google Translate struggles from this issue!!!!\n",
        "   * MUST WATCH! [MT hallucination videos](https://youtube.com/playlist?list=PLdH9u0f1XKW8xMTey65vsmZEH-ib2cFDz)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"mememememememememememe\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.2 --max-len-b 10 \\\n",
        "    --beam 1000 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cfa398-f3c3-428e-86d3-f91b57767965",
        "id": "pzziJBCAcM2W"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁mem em em em em em em em em eme\n",
            "W-0\t0.499\tseconds\n",
            "H-0\t-1.514109492301941\t▁Germany ' s ▁enem y ▁em ph as is .\n",
            "D-0\t-1.514109492301941\tGermany's enemy emphasis.\n",
            "P-0\t-5.9265 -0.8541 -0.0824 -4.6888 -0.2200 -0.6711 -3.4153 -0.3387 -0.2244 -0.1297 -0.1041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_gm97-YNgDV"
      },
      "source": [
        "### How to spot \n",
        "  \n",
        "  * Human Evaluation! It is tricky ([Paper](https://arxiv.org/abs/2005.00661)).\n",
        "\n",
        " * Learned metric: BLEURT: BERT trained to match human judgement.\n",
        "\n",
        "Pre-trained models can be utilized as evaluators too. [Paper](https://arxiv.org/abs/2004.04696).\n",
        "\n",
        "The final model is the '**reference [sep] candidate**' scorer:\n",
        "\n",
        "$$\n",
        "\\text{score} = Wv_\\text{[CLS]} + b,\\\\\n",
        "v_\\text{[CLS]} = f_\\text{BERT}(ref,cand)\n",
        "$$\n",
        "\n",
        "\n",
        "![](https://1.bp.blogspot.com/-RoK03xeSsJ4/XtFYBk7o0ZI/AAAAAAAAGCc/NhvgzVsZfRALLZMmz_XRvxAr9-tcsurGQCLcBGAsYHQ/s400/image4.png)\n",
        "\n",
        "\n",
        "![](https://1.bp.blogspot.com/-AtLJNnE7Kwc/XtFXyqAPjrI/AAAAAAAAGCU/C-WHyQ-XRxUceITNwpY-TqgHJAfCrxIUwCLcBGAsYHQ/s640/image1.png)\n",
        "\n",
        "Note: when doing not a translation task, better use the BERTScore version [Paper](https://arxiv.org/abs/1904.09675)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tricks (are there any?):\n",
        "\n",
        "* If we know what to output (entities): Controllable generation! Grid beam search / [DBA](https://aclanthology.org/N18-1119/). "
      ],
      "metadata": {
        "id": "zbwdAzQtcM2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Tc4vTYo4NX5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448931b3-b7f2-4414-9780-10111c112035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁inc or re ct ly ▁ @ - @ <unk> ▁ @ - @ <unk>\n",
            "W-0\t1.250\tseconds\n",
            "H-0\t-1.0155543088912964\t▁I ▁don ' t ▁know ▁what ' s ▁wrong ▁with ▁ @ - @ - @ - @ - @ - @ - @ - @ .\n",
            "D-0\t-1.0155543088912964\tI don't know what's wrong with @-@-@-@-@-@-@-@.\n",
            "P-0\t-1.6561 -1.8993 -0.1067 -0.0876 -1.2509 -1.6152 -3.2709 -0.0950 -1.8132 -0.0814 -1.9699 -0.1227 -2.1880 -0.2766 -1.0654 -0.3045 -0.9522 -0.3603 -0.7154 -0.4295 -0.6346 -0.4882 -0.9167 -0.5681 -1.2629 -0.7358 -3.5460 -0.0223\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo \"incorrectly-formed-sequence\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.2 --max-len-b 10 \\\n",
        "    --beam 1000 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stdout\n",
        "%%bash\n",
        "echo -e \"incorrectly-formed-sequence\\tincorrectly\\tformed\\tsequence\" | fairseq-interactive \\\n",
        "    --path /content/iwslt17fren.pt /content/iwslt-data  \\\n",
        "    --tokenizer moses --bpe sentencepiece --max-len-a 1.2 --max-len-b 10 \\\n",
        "    --beam 1000 --nbest 1 \\\n",
        "    --source-lang fr --target-lang en \\\n",
        "    --remove-bpe --constraints --sentencepiece-model /content/iwslt-data/sentencepiece.bpe.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtIGAFZpVWNl",
        "outputId": "f20b0b2d-2eeb-484b-e8d5-e5ad3ed12745"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S-0\t▁inc or re ct ly ▁ @ - @ <unk> ▁ @ - @ <unk>\n",
            "W-0\t25.563\tseconds\n",
            "C-0\t▁inc or re ct ly\n",
            "C-0\t▁formed\n",
            "C-0\t▁sequence\n",
            "H-0\t-2.040598154067993\t▁I ▁mean , ▁it ' s ▁inc or re ct ly ▁ @ - @ - @ - @ - @ - @ - @ ▁formed . ▁sequence .\n",
            "D-0\t-2.040598154067993\tI mean, it's incorrectly @-@-@-@-@-@-@ formed. sequence.\n",
            "P-0\t-1.6561 -3.1994 -0.1526 -3.4081 -0.3667 -0.1034 -7.1732 -0.0190 -0.0316 -0.0014 -0.0579 -0.2736 -0.1398 -1.0432 -0.2758 -1.9315 -0.2759 -1.4401 -0.3219 -0.8928 -0.3760 -0.8968 -0.4262 -1.3673 -0.5280 -16.9617 -0.1014 -16.6280 -1.0584 -0.1098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remedies\n",
        "\n",
        "* Unlikelihood loss [Paper](https://arxiv.org/pdf/1908.04319.pdf). We observe that low-frequency tokens are less likely under the model than high-frequency tokens. Explicitly mimimizing the probability of negative samples on every timestep helps. Stay tuned for the research talk on Friday"
      ],
      "metadata": {
        "id": "4gWzrHKTUq0E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vb5fxSl2NX2s"
      },
      "outputs": [],
      "source": [
        "# hallucinations e.g what does google translate this sequence:\n",
        "# Hawaiian: aoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoaoao\n",
        "# English: you love me you love me you love me you love me you love me."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-fMvERENX0s"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WziZVihNNXeB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za3evy5kaA6u"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr8IjstAaA6u"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcEjbzsoHcsL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "iMOyeRaP1-Sf"
      ],
      "name": "Stephen Kiilu day3-lab-decoding-strategies.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b643c5f9f2c496d89442eae620c5776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b42d711555a4411b0d42488729e8256",
              "IPY_MODEL_6ad1abd312f140c389f262106f9c7156",
              "IPY_MODEL_3e8a6697f7b5440d9c1a77a994cf0b89"
            ],
            "layout": "IPY_MODEL_0ede99c142d44a349a7408b0f15d3b1e"
          }
        },
        "6b42d711555a4411b0d42488729e8256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9b29157b3eb402cba6e851adb7c3aa4",
            "placeholder": "​",
            "style": "IPY_MODEL_4eeb2b4141df47fa911020a186b5daa0",
            "value": "Downloading: 100%"
          }
        },
        "6ad1abd312f140c389f262106f9c7156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0f2d41281f049e9be727cb316cf3550",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d462afe17fd7406b9f01276e3b720495",
            "value": 1042301
          }
        },
        "3e8a6697f7b5440d9c1a77a994cf0b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6508da61dbe497bbf4c00d761c9cd04",
            "placeholder": "​",
            "style": "IPY_MODEL_95e5c61b03fb49d396a00c06ea1bb043",
            "value": " 0.99M/0.99M [00:00&lt;00:00, 1.57MB/s]"
          }
        },
        "0ede99c142d44a349a7408b0f15d3b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9b29157b3eb402cba6e851adb7c3aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eeb2b4141df47fa911020a186b5daa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0f2d41281f049e9be727cb316cf3550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d462afe17fd7406b9f01276e3b720495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6508da61dbe497bbf4c00d761c9cd04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e5c61b03fb49d396a00c06ea1bb043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b386d0a3ef34844acd1db0d57adaa49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1d5262840314db9bbb3e355153bbd35",
              "IPY_MODEL_fa2cc1a6c450403193b66dde7ae9ac82",
              "IPY_MODEL_9c16b34475a04bf2a04634c1b8da8acc"
            ],
            "layout": "IPY_MODEL_9a870d56790f4f08804e3ddf62098224"
          }
        },
        "e1d5262840314db9bbb3e355153bbd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_883c7b850e7d4278950fc9ddbd9bfe0d",
            "placeholder": "​",
            "style": "IPY_MODEL_06ee500b3d6d4fa59e32ee8528952bc9",
            "value": "Downloading: 100%"
          }
        },
        "fa2cc1a6c450403193b66dde7ae9ac82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73a27099528747a9bf7c015a69c009ee",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf6b2652a00d453ca9da39081a9bd0e3",
            "value": 456318
          }
        },
        "9c16b34475a04bf2a04634c1b8da8acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc5023b78c7a460eaf1378e47976c3f1",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed9ac5af51d4137ab62f8b8ed64efe3",
            "value": " 446k/446k [00:00&lt;00:00, 1.58MB/s]"
          }
        },
        "9a870d56790f4f08804e3ddf62098224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883c7b850e7d4278950fc9ddbd9bfe0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ee500b3d6d4fa59e32ee8528952bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73a27099528747a9bf7c015a69c009ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf6b2652a00d453ca9da39081a9bd0e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc5023b78c7a460eaf1378e47976c3f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed9ac5af51d4137ab62f8b8ed64efe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5ca46abe1c9449f8cb219c03e27954e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_517412aa83874dcfada3806c2185c4fc",
              "IPY_MODEL_ab9bc6e6e89841968fda99567d3ce71c",
              "IPY_MODEL_98943bdc08624ac3b41fb1bc35c485af"
            ],
            "layout": "IPY_MODEL_4249890508d144f59d1df54552f56e32"
          }
        },
        "517412aa83874dcfada3806c2185c4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07ac260cb38c48478c0845571337a365",
            "placeholder": "​",
            "style": "IPY_MODEL_f4a249f3c2ae46d797bccf2074517af9",
            "value": "Downloading: 100%"
          }
        },
        "ab9bc6e6e89841968fda99567d3ce71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283d3438bc504ef6858724dd66d61d2a",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbf7092108ed441393078c6b1c866037",
            "value": 665
          }
        },
        "98943bdc08624ac3b41fb1bc35c485af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9479f49f27f648319d8cb9f8e4241b4f",
            "placeholder": "​",
            "style": "IPY_MODEL_e05206ab890d4b7c9e9bc0a5e76c36ce",
            "value": " 665/665 [00:00&lt;00:00, 22.0kB/s]"
          }
        },
        "4249890508d144f59d1df54552f56e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ac260cb38c48478c0845571337a365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a249f3c2ae46d797bccf2074517af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "283d3438bc504ef6858724dd66d61d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf7092108ed441393078c6b1c866037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9479f49f27f648319d8cb9f8e4241b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05206ab890d4b7c9e9bc0a5e76c36ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3ebd30ef736466f96ee33b57504c8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7e5c80b4b4741aeaa7c546c6bc4141c",
              "IPY_MODEL_6247806e25bd4820be23ba73a2f97889",
              "IPY_MODEL_57dde0446ce844fb97f8be8b705633ef"
            ],
            "layout": "IPY_MODEL_09c91683dbac4ac69b24566c0afb5f5a"
          }
        },
        "b7e5c80b4b4741aeaa7c546c6bc4141c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e61c21f7f36942a3b7aa1b5c5fce83ea",
            "placeholder": "​",
            "style": "IPY_MODEL_8ff7af986ba641b98a233a10a9ff8312",
            "value": "Downloading: 100%"
          }
        },
        "6247806e25bd4820be23ba73a2f97889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1259da7ec8944f24bbcc765537edf2ae",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78dbeebd864242899a81b117f719bc84",
            "value": 548118077
          }
        },
        "57dde0446ce844fb97f8be8b705633ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00a88d1d0f6e4607b1da28a327b3dfc3",
            "placeholder": "​",
            "style": "IPY_MODEL_f395dfdadd544a4cbb9e25fd20e1f912",
            "value": " 523M/523M [00:15&lt;00:00, 57.8MB/s]"
          }
        },
        "09c91683dbac4ac69b24566c0afb5f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e61c21f7f36942a3b7aa1b5c5fce83ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ff7af986ba641b98a233a10a9ff8312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1259da7ec8944f24bbcc765537edf2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78dbeebd864242899a81b117f719bc84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00a88d1d0f6e4607b1da28a327b3dfc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f395dfdadd544a4cbb9e25fd20e1f912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}